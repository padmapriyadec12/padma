{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import neighbors,preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release</th>\n",
       "      <th>n_0000</th>\n",
       "      <th>n_0001</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0003</th>\n",
       "      <th>n_0004</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0006</th>\n",
       "      <th>n_0007</th>\n",
       "      <th>...</th>\n",
       "      <th>c_1368</th>\n",
       "      <th>c_1369</th>\n",
       "      <th>c_1370</th>\n",
       "      <th>c_1371</th>\n",
       "      <th>c_1372</th>\n",
       "      <th>c_1373</th>\n",
       "      <th>c_1374</th>\n",
       "      <th>c_1375</th>\n",
       "      <th>c_1376</th>\n",
       "      <th>c_1377</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262</td>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id release  n_0000  n_0001    n_0002  n_0003  n_0004    n_0005  n_0006  \\\n",
       "0  11193       a     NaN     NaN  0.025449     NaN     NaN  0.368421     NaN   \n",
       "1  11382       a     NaN     NaN  0.031297     NaN     NaN  0.315789     NaN   \n",
       "2  16531       a     NaN     NaN  0.024475     NaN     NaN  0.342105     NaN   \n",
       "3   1896       a     NaN     NaN  0.041694     NaN     NaN  0.447368     NaN   \n",
       "4  18262       c     NaN     NaN  0.038120     NaN     NaN  0.315789     NaN   \n",
       "\n",
       "   n_0007   ...    c_1368  c_1369  c_1370  c_1371  c_1372  c_1373  c_1374  \\\n",
       "0     NaN   ...       NaN     NaN     NaN     NaN       a     NaN       q   \n",
       "1     NaN   ...       NaN     NaN       a     NaN       a     NaN     NaN   \n",
       "2     NaN   ...       NaN     NaN       a     NaN       a     NaN       b   \n",
       "3     NaN   ...       NaN     NaN     NaN     NaN       a     NaN     NaN   \n",
       "4     NaN   ...       NaN     NaN       b     NaN       a     NaN       a   \n",
       "\n",
       "   c_1375  c_1376  c_1377  \n",
       "0     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 1379 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data \n",
    "train_data= pd.read_csv(\"D:\\\\Capstone project\\\\Capstone Project\\\\train Data.csv\",low_memory=False)\n",
    "#print(train_data.columns.values),low_memory=False\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14644, 1379)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'release', 'n_0000', 'n_0001', 'n_0002', 'n_0003', 'n_0004',\n",
       "       'n_0005', 'n_0006', 'n_0007',\n",
       "       ...\n",
       "       'c_1368', 'c_1369', 'c_1370', 'c_1371', 'c_1372', 'c_1373', 'c_1374',\n",
       "       'c_1375', 'c_1376', 'c_1377'],\n",
       "      dtype='object', length=1379)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating dataframe for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missdf=pd.DataFrame({'cols':train_data.columns.values,\n",
    "                          'missing':list(train_data.isnull().sum())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missdf['missingPerc'] = missdf.missing/train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cols</th>\n",
       "      <th>missing</th>\n",
       "      <th>missingPerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>release</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_0000</td>\n",
       "      <td>14625</td>\n",
       "      <td>0.998703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_0001</td>\n",
       "      <td>13884</td>\n",
       "      <td>0.948102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_0002</td>\n",
       "      <td>644</td>\n",
       "      <td>0.043977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cols  missing  missingPerc\n",
       "0       id        0     0.000000\n",
       "1  release        0     0.000000\n",
       "2   n_0000    14625     0.998703\n",
       "3   n_0001    13884     0.948102\n",
       "4   n_0002      644     0.043977"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#percentage of missing data\n",
    "train_data1=pd.DataFrame(train_data[missdf[missdf['missingPerc']<0.8]['cols']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14644 entries, 0 to 14643\n",
      "Columns: 341 entries, id to c_1377\n",
      "dtypes: float64(63), int64(9), object(269)\n",
      "memory usage: 38.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data after removal of null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>release</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0012</th>\n",
       "      <th>n_0019</th>\n",
       "      <th>n_0028</th>\n",
       "      <th>n_0034</th>\n",
       "      <th>n_0038</th>\n",
       "      <th>n_0039</th>\n",
       "      <th>...</th>\n",
       "      <th>c_1333</th>\n",
       "      <th>c_1335</th>\n",
       "      <th>c_1343</th>\n",
       "      <th>c_1347</th>\n",
       "      <th>c_1348</th>\n",
       "      <th>c_1361</th>\n",
       "      <th>c_1363</th>\n",
       "      <th>c_1372</th>\n",
       "      <th>c_1374</th>\n",
       "      <th>c_1377</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193</td>\n",
       "      <td>a</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>q</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382</td>\n",
       "      <td>a</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>q</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531</td>\n",
       "      <td>a</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>u</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>a</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262</td>\n",
       "      <td>c</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id release    n_0002    n_0005    n_0012  n_0019  n_0028    n_0034  \\\n",
       "0  11193       a  0.025449  0.368421  0.292683     0.0     NaN  0.223881   \n",
       "1  11382       a  0.031297  0.315789  0.243902     0.0     NaN  0.104478   \n",
       "2  16531       a  0.024475  0.342105  0.304878     0.0     NaN  0.119403   \n",
       "3   1896       a  0.041694  0.447368  0.207317     0.0     NaN  0.149254   \n",
       "4  18262       c  0.038120  0.315789  0.219512     0.0     NaN  0.074627   \n",
       "\n",
       "     n_0038  n_0039   ...    c_1333  c_1335  c_1343  c_1347  c_1348  c_1361  \\\n",
       "0  0.193548     NaN   ...         e       w       b     NaN       b       e   \n",
       "1  0.177419     NaN   ...         e       q       b     NaN       b       e   \n",
       "2  0.290323     NaN   ...         e       u       a     NaN       b       c   \n",
       "3  0.370968     NaN   ...       NaN       w       a     NaN       b       g   \n",
       "4  0.177419  0.3125   ...         e       b       b       d       b       e   \n",
       "\n",
       "   c_1363  c_1372  c_1374  c_1377  \n",
       "0       b       a       q     NaN  \n",
       "1       b       a     NaN     NaN  \n",
       "2       a       a       b     NaN  \n",
       "3       a       a     NaN     NaN  \n",
       "4       b       a       a     NaN  \n",
       "\n",
       "[5 rows x 341 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cols=train_data1.columns\n",
    "cols=train_data1.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data of Numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0012</th>\n",
       "      <th>n_0019</th>\n",
       "      <th>n_0028</th>\n",
       "      <th>n_0034</th>\n",
       "      <th>n_0038</th>\n",
       "      <th>n_0039</th>\n",
       "      <th>n_0047</th>\n",
       "      <th>...</th>\n",
       "      <th>o_0270</th>\n",
       "      <th>o_0274</th>\n",
       "      <th>o_0276</th>\n",
       "      <th>o_0279</th>\n",
       "      <th>o_0285</th>\n",
       "      <th>o_0286</th>\n",
       "      <th>o_0301</th>\n",
       "      <th>o_0314</th>\n",
       "      <th>o_0315</th>\n",
       "      <th>o_0323</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    n_0002    n_0005    n_0012  n_0019  n_0028    n_0034    n_0038  \\\n",
       "0  11193  0.025449  0.368421  0.292683     0.0     NaN  0.223881  0.193548   \n",
       "1  11382  0.031297  0.315789  0.243902     0.0     NaN  0.104478  0.177419   \n",
       "2  16531  0.024475  0.342105  0.304878     0.0     NaN  0.119403  0.290323   \n",
       "3   1896  0.041694  0.447368  0.207317     0.0     NaN  0.149254  0.370968   \n",
       "4  18262  0.038120  0.315789  0.219512     0.0     NaN  0.074627  0.177419   \n",
       "\n",
       "   n_0039  n_0047   ...    o_0270  o_0274  o_0276  o_0279  o_0285  o_0286  \\\n",
       "0     NaN       1   ...       NaN    27.0     NaN    10.0     NaN    15.0   \n",
       "1     NaN       1   ...       6.0    33.0     NaN    14.0     NaN    14.0   \n",
       "2     NaN       1   ...       3.0    23.0     NaN    32.0     NaN     5.0   \n",
       "3     NaN       1   ...       6.0    46.0     NaN     NaN     NaN    30.0   \n",
       "4  0.3125       1   ...       9.0    40.0     NaN    20.0     NaN    19.0   \n",
       "\n",
       "   o_0301  o_0314  o_0315  o_0323  \n",
       "0    12.0     NaN     0.0     NaN  \n",
       "1    10.0     NaN     0.0     NaN  \n",
       "2     6.0     NaN     NaN     NaN  \n",
       "3     8.0     NaN     0.0     NaN  \n",
       "4    13.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data1.select_dtypes(exclude=['object'])\n",
    "num_cols=pd.DataFrame(train_data1.select_dtypes(include=['number']))\n",
    "num_cols.head()\n",
    "#train_data1.select_dtypes(include=['number']).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'n_0002', 'n_0005', 'n_0012', 'n_0019', 'n_0028', 'n_0034',\n",
       "       'n_0038', 'n_0039', 'n_0047', 'n_0048', 'n_0050', 'n_0051', 'n_0052',\n",
       "       'n_0059', 'n_0060', 'n_0061', 'n_0064', 'n_0066', 'n_0067', 'n_0071',\n",
       "       'n_0074', 'n_0075', 'n_0078', 'n_0083', 'n_0086', 'n_0091', 'n_0095',\n",
       "       'n_0099', 'n_0100', 'n_0102', 'n_0108', 'n_0109', 'n_0110', 'o_0120',\n",
       "       'o_0125', 'o_0129', 'o_0132', 'o_0141', 'o_0144', 'o_0147', 'o_0152',\n",
       "       'o_0153', 'o_0154', 'o_0157', 'o_0168', 'o_0175', 'o_0176', 'o_0179',\n",
       "       'o_0201', 'o_0202', 'o_0208', 'o_0217', 'o_0221', 'o_0223', 'o_0230',\n",
       "       'o_0231', 'o_0241', 'o_0248', 'o_0264', 'o_0265', 'o_0268', 'o_0270',\n",
       "       'o_0274', 'o_0276', 'o_0279', 'o_0285', 'o_0286', 'o_0301', 'o_0314',\n",
       "       'o_0315', 'o_0323'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values of numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>n_0002</th>\n",
       "      <th>n_0005</th>\n",
       "      <th>n_0012</th>\n",
       "      <th>n_0019</th>\n",
       "      <th>n_0028</th>\n",
       "      <th>n_0034</th>\n",
       "      <th>n_0038</th>\n",
       "      <th>n_0039</th>\n",
       "      <th>n_0047</th>\n",
       "      <th>...</th>\n",
       "      <th>o_0270</th>\n",
       "      <th>o_0274</th>\n",
       "      <th>o_0276</th>\n",
       "      <th>o_0279</th>\n",
       "      <th>o_0285</th>\n",
       "      <th>o_0286</th>\n",
       "      <th>o_0301</th>\n",
       "      <th>o_0314</th>\n",
       "      <th>o_0315</th>\n",
       "      <th>o_0323</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11193.0</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.223881</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11382.0</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16531.0</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.304878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1896.0</td>\n",
       "      <td>0.041694</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18262.0</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    n_0002    n_0005    n_0012  n_0019    n_0028    n_0034  \\\n",
       "0  11193.0  0.025449  0.368421  0.292683     0.0  0.045455  0.223881   \n",
       "1  11382.0  0.031297  0.315789  0.243902     0.0  0.045455  0.104478   \n",
       "2  16531.0  0.024475  0.342105  0.304878     0.0  0.045455  0.119403   \n",
       "3   1896.0  0.041694  0.447368  0.207317     0.0  0.045455  0.149254   \n",
       "4  18262.0  0.038120  0.315789  0.219512     0.0  0.045455  0.074627   \n",
       "\n",
       "     n_0038    n_0039  n_0047   ...    o_0270  o_0274  o_0276  o_0279  o_0285  \\\n",
       "0  0.193548  0.208333     1.0   ...       5.0    27.0     1.0    10.0     1.0   \n",
       "1  0.177419  0.208333     1.0   ...       6.0    33.0     1.0    14.0     1.0   \n",
       "2  0.290323  0.208333     1.0   ...       3.0    23.0     1.0    32.0     1.0   \n",
       "3  0.370968  0.208333     1.0   ...       6.0    46.0     1.0    29.0     1.0   \n",
       "4  0.177419  0.312500     1.0   ...       9.0    40.0     1.0    20.0     1.0   \n",
       "\n",
       "   o_0286  o_0301  o_0314  o_0315  o_0323  \n",
       "0    15.0    12.0     0.0     0.0     0.0  \n",
       "1    14.0    10.0     0.0     0.0     0.0  \n",
       "2     5.0     6.0     0.0     0.0     0.0  \n",
       "3    30.0     8.0     0.0     0.0     0.0  \n",
       "4    19.0    13.0     0.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer=Imputer(missing_values=np.nan, strategy='median', axis=0)\n",
    "imputer=imputer.fit(num_cols)\n",
    "imputed_data=imputer.transform(num_cols.values)\n",
    "num_cols1=pd.DataFrame(imputed_data,columns=num_cols.columns)\n",
    "num_cols1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "num_cols1 = StandardScaler().fit_transform(num_cols1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=0.8, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(.80)## It explains only 80% of information of data (variance)\n",
    "#pca = PCA(n_components=30)\n",
    "print(pca)\n",
    "num_cols2=pca.fit_transform(num_cols1)\n",
    "#pca.explained_variance_ratio_\n",
    "pca_components=pca.n_components_\n",
    "pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10957094  0.05517021  0.04353973  0.03887716  0.03235958  0.02671965\n",
      "  0.02628239  0.02242339  0.01999731  0.01939875  0.01849289  0.01823029\n",
      "  0.01749316  0.01729571  0.01646379  0.01613038  0.01593858  0.01572859\n",
      "  0.01567793  0.0156186   0.01535169  0.01512557  0.01502345  0.01482267\n",
      "  0.01472097  0.01458605  0.01449421  0.01438068  0.01397057  0.01387584\n",
      "  0.01347677  0.0132305   0.01300499  0.01281318  0.0125942   0.01246074\n",
      "  0.01244183  0.01206752]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18b64a36d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "print(var)\n",
    "plt.plot(var)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Dataframe after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.076627</td>\n",
       "      <td>-0.575677</td>\n",
       "      <td>-0.841880</td>\n",
       "      <td>2.313944</td>\n",
       "      <td>0.844188</td>\n",
       "      <td>-1.124082</td>\n",
       "      <td>-2.584006</td>\n",
       "      <td>-0.594535</td>\n",
       "      <td>0.939601</td>\n",
       "      <td>-0.818944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232521</td>\n",
       "      <td>-0.236592</td>\n",
       "      <td>0.908256</td>\n",
       "      <td>0.185777</td>\n",
       "      <td>0.063665</td>\n",
       "      <td>0.162707</td>\n",
       "      <td>-0.689815</td>\n",
       "      <td>1.252231</td>\n",
       "      <td>0.786739</td>\n",
       "      <td>0.841315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.836042</td>\n",
       "      <td>0.261186</td>\n",
       "      <td>-0.171489</td>\n",
       "      <td>2.210323</td>\n",
       "      <td>-0.552976</td>\n",
       "      <td>-1.470234</td>\n",
       "      <td>-0.944588</td>\n",
       "      <td>-0.087564</td>\n",
       "      <td>0.673511</td>\n",
       "      <td>0.924485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741431</td>\n",
       "      <td>-0.466551</td>\n",
       "      <td>-0.285145</td>\n",
       "      <td>0.452369</td>\n",
       "      <td>-0.418338</td>\n",
       "      <td>-0.061422</td>\n",
       "      <td>1.132073</td>\n",
       "      <td>0.632208</td>\n",
       "      <td>0.095734</td>\n",
       "      <td>0.971994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.018008</td>\n",
       "      <td>3.167597</td>\n",
       "      <td>-0.223201</td>\n",
       "      <td>-1.768088</td>\n",
       "      <td>-0.478885</td>\n",
       "      <td>-2.902527</td>\n",
       "      <td>0.474748</td>\n",
       "      <td>-0.042028</td>\n",
       "      <td>-0.159062</td>\n",
       "      <td>0.415008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048935</td>\n",
       "      <td>0.937004</td>\n",
       "      <td>-0.931084</td>\n",
       "      <td>1.254646</td>\n",
       "      <td>-1.259625</td>\n",
       "      <td>-0.150548</td>\n",
       "      <td>-0.322628</td>\n",
       "      <td>-0.026147</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>-0.705993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770249</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>-0.247511</td>\n",
       "      <td>-1.506793</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>1.277786</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>1.994898</td>\n",
       "      <td>-0.369985</td>\n",
       "      <td>-0.451570</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.241423</td>\n",
       "      <td>0.371171</td>\n",
       "      <td>-0.443772</td>\n",
       "      <td>-1.119460</td>\n",
       "      <td>1.656568</td>\n",
       "      <td>-0.067804</td>\n",
       "      <td>-1.059020</td>\n",
       "      <td>-0.835921</td>\n",
       "      <td>0.613648</td>\n",
       "      <td>-0.869783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.525670</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>3.045903</td>\n",
       "      <td>1.629937</td>\n",
       "      <td>-2.787773</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>-2.714656</td>\n",
       "      <td>1.502891</td>\n",
       "      <td>0.979560</td>\n",
       "      <td>2.698379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190738</td>\n",
       "      <td>-1.264388</td>\n",
       "      <td>-0.912625</td>\n",
       "      <td>1.190297</td>\n",
       "      <td>0.039980</td>\n",
       "      <td>-1.009747</td>\n",
       "      <td>-0.134169</td>\n",
       "      <td>0.374120</td>\n",
       "      <td>-1.175972</td>\n",
       "      <td>-1.003526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  6.076627 -0.575677 -0.841880  2.313944  0.844188 -1.124082 -2.584006   \n",
       "1  3.836042  0.261186 -0.171489  2.210323 -0.552976 -1.470234 -0.944588   \n",
       "2  4.018008  3.167597 -0.223201 -1.768088 -0.478885 -2.902527  0.474748   \n",
       "3  0.770249  0.819915 -0.247511 -1.506793  0.210980  1.277786  0.028599   \n",
       "4  1.525670  0.431122  3.045903  1.629937 -2.787773  0.009762 -2.714656   \n",
       "\n",
       "         7         8         9     ...           28        29        30  \\\n",
       "0 -0.594535  0.939601 -0.818944    ...    -0.232521 -0.236592  0.908256   \n",
       "1 -0.087564  0.673511  0.924485    ...     0.741431 -0.466551 -0.285145   \n",
       "2 -0.042028 -0.159062  0.415008    ...    -0.048935  0.937004 -0.931084   \n",
       "3  1.994898 -0.369985 -0.451570    ...    -1.241423  0.371171 -0.443772   \n",
       "4  1.502891  0.979560  2.698379    ...    -0.190738 -1.264388 -0.912625   \n",
       "\n",
       "         31        32        33        34        35        36        37  \n",
       "0  0.185777  0.063665  0.162707 -0.689815  1.252231  0.786739  0.841315  \n",
       "1  0.452369 -0.418338 -0.061422  1.132073  0.632208  0.095734  0.971994  \n",
       "2  1.254646 -1.259625 -0.150548 -0.322628 -0.026147  0.010269 -0.705993  \n",
       "3 -1.119460  1.656568 -0.067804 -1.059020 -0.835921  0.613648 -0.869783  \n",
       "4  1.190297  0.039980 -1.009747 -0.134169  0.374120 -1.175972 -1.003526  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols3=pd.DataFrame(num_cols2,columns=range(pca_components))\n",
    "num_cols3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill missing values with fillna() method----Another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num_cols.fillna(num_cols.mean(), inplace=True)\n",
    "#num_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data of categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release</th>\n",
       "      <th>c_0332</th>\n",
       "      <th>c_0337</th>\n",
       "      <th>c_0339</th>\n",
       "      <th>c_0348</th>\n",
       "      <th>c_0351</th>\n",
       "      <th>c_0357</th>\n",
       "      <th>c_0361</th>\n",
       "      <th>c_0364</th>\n",
       "      <th>c_0368</th>\n",
       "      <th>...</th>\n",
       "      <th>c_1333</th>\n",
       "      <th>c_1335</th>\n",
       "      <th>c_1343</th>\n",
       "      <th>c_1347</th>\n",
       "      <th>c_1348</th>\n",
       "      <th>c_1361</th>\n",
       "      <th>c_1363</th>\n",
       "      <th>c_1372</th>\n",
       "      <th>c_1374</th>\n",
       "      <th>c_1377</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>q</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>q</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>u</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  release c_0332 c_0337 c_0339 c_0348 c_0351 c_0357 c_0361 c_0364 c_0368  \\\n",
       "0       a    NaN      a    NaN      f      o    NaN    NaN      a      b   \n",
       "1       a    NaN      a    NaN      k      s    NaN    NaN      a      b   \n",
       "2       a    NaN      b    NaN      p      f    NaN    NaN      b      b   \n",
       "3       a    NaN      a    NaN      f      o    NaN    NaN      b      b   \n",
       "4       c      a      a      b      t      c    NaN      b      a      b   \n",
       "\n",
       "   ...   c_1333 c_1335 c_1343 c_1347 c_1348 c_1361 c_1363 c_1372 c_1374 c_1377  \n",
       "0  ...        e      w      b    NaN      b      e      b      a      q    NaN  \n",
       "1  ...        e      q      b    NaN      b      e      b      a    NaN    NaN  \n",
       "2  ...        e      u      a    NaN      b      c      a      a      b    NaN  \n",
       "3  ...      NaN      w      a    NaN      b      g      a      a    NaN    NaN  \n",
       "4  ...        e      b      b      d      b      e      b      a      a    NaN  \n",
       "\n",
       "[5 rows x 269 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols=pd.DataFrame(train_data1.select_dtypes(include=['object']))\n",
    "cat_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "release        0\n",
       "c_0332     11478\n",
       "c_0337      4559\n",
       "c_0339     11473\n",
       "c_0348      5810\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols.isnull().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['a', nan, 'a', ..., 'a', 'q', nan],\n",
       "       ['a', nan, 'a', ..., 'a', nan, nan],\n",
       "       ['a', nan, 'b', ..., 'a', 'b', nan],\n",
       "       ..., \n",
       "       ['c', 'a', 'b', ..., 'a', nan, 'b'],\n",
       "       ['b', nan, nan, ..., 'a', nan, nan],\n",
       "       ['a', nan, 'a', ..., 'a', nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer =Imputer(missing_values=np.nan, strategy='most_frequent', axis=0)\n",
    "imputer=imputer.fit(cat_cols)\n",
    "imputed_data=imputer.transform(cat_cols.values)\n",
    "cat_cols1=pd.DataFrame(imputed_data,columns=cat_cols.columns)\n",
    "cat_cols1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "release        0\n",
       "c_0332     11478\n",
       "c_0337      4559\n",
       "c_0339     11473\n",
       "c_0348      5810\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols.isnull().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release</th>\n",
       "      <th>c_0332</th>\n",
       "      <th>c_0337</th>\n",
       "      <th>c_0339</th>\n",
       "      <th>c_0348</th>\n",
       "      <th>c_0351</th>\n",
       "      <th>c_0357</th>\n",
       "      <th>c_0361</th>\n",
       "      <th>c_0364</th>\n",
       "      <th>c_0368</th>\n",
       "      <th>...</th>\n",
       "      <th>c_1333</th>\n",
       "      <th>c_1335</th>\n",
       "      <th>c_1343</th>\n",
       "      <th>c_1347</th>\n",
       "      <th>c_1348</th>\n",
       "      <th>c_1361</th>\n",
       "      <th>c_1363</th>\n",
       "      <th>c_1372</th>\n",
       "      <th>c_1374</th>\n",
       "      <th>c_1377</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>q</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>q</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>u</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  release c_0332 c_0337 c_0339 c_0348 c_0351 c_0357 c_0361 c_0364 c_0368  \\\n",
       "0       a    NaN      a    NaN      f      o    NaN    NaN      a      b   \n",
       "1       a    NaN      a    NaN      k      s    NaN    NaN      a      b   \n",
       "2       a    NaN      b    NaN      p      f    NaN    NaN      b      b   \n",
       "3       a    NaN      a    NaN      f      o    NaN    NaN      b      b   \n",
       "4       c      a      a      b      t      c    NaN      b      a      b   \n",
       "\n",
       "   ...   c_1333 c_1335 c_1343 c_1347 c_1348 c_1361 c_1363 c_1372 c_1374 c_1377  \n",
       "0  ...        e      w      b    NaN      b      e      b      a      q    NaN  \n",
       "1  ...        e      q      b    NaN      b      e      b      a    NaN    NaN  \n",
       "2  ...        e      u      a    NaN      b      c      a      a      b    NaN  \n",
       "3  ...      NaN      w      a    NaN      b      g      a      a    NaN    NaN  \n",
       "4  ...        e      b      b      d      b      e      b      a      a    NaN  \n",
       "\n",
       "[5 rows x 269 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le =LabelEncoder()\n",
    "le.fit_transform(cat_cols[cat_cols.columns[0]])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-da1ce1ff8978>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mle\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mencoded_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1971\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1641\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1643\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1645\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "X=cat_cols\n",
    "X.shape[1]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le =LabelEncoder()\n",
    "# encode string input values as integers\n",
    "features = []\n",
    "for i in range(0, X.shape[1]):\n",
    "    le= LabelEncoder()\n",
    "    feature = le.fit_transform(X[:,i])\n",
    "    features.append(feature)\n",
    "encoded_x = numpy.array(features)\n",
    "encoded_x = encoded_x.reshape(X.shape[0], X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#enc = OneHotEncoder()\n",
    "#X = enc.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummies for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_b</th>\n",
       "      <th>release_c</th>\n",
       "      <th>c_0332_b</th>\n",
       "      <th>c_0337_b</th>\n",
       "      <th>c_0339_b</th>\n",
       "      <th>c_0348_b</th>\n",
       "      <th>c_0348_c</th>\n",
       "      <th>c_0348_d</th>\n",
       "      <th>c_0348_e</th>\n",
       "      <th>c_0348_f</th>\n",
       "      <th>...</th>\n",
       "      <th>c_1374_p</th>\n",
       "      <th>c_1374_q</th>\n",
       "      <th>c_1374_r</th>\n",
       "      <th>c_1374_s</th>\n",
       "      <th>c_1374_t</th>\n",
       "      <th>c_1374_u</th>\n",
       "      <th>c_1374_v</th>\n",
       "      <th>c_1374_w</th>\n",
       "      <th>c_1374_x</th>\n",
       "      <th>c_1377_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   release_b  release_c  c_0332_b  c_0337_b  c_0339_b  c_0348_b  c_0348_c  \\\n",
       "0          0          0         0         0         0         0         0   \n",
       "1          0          0         0         0         0         0         0   \n",
       "2          0          0         0         1         0         0         0   \n",
       "3          0          0         0         0         0         0         0   \n",
       "4          0          1         0         0         1         0         0   \n",
       "\n",
       "   c_0348_d  c_0348_e  c_0348_f    ...     c_1374_p  c_1374_q  c_1374_r  \\\n",
       "0         0         0         1    ...            0         1         0   \n",
       "1         0         0         0    ...            0         0         0   \n",
       "2         0         0         0    ...            0         0         0   \n",
       "3         0         0         1    ...            0         0         0   \n",
       "4         0         0         0    ...            0         0         0   \n",
       "\n",
       "   c_1374_s  c_1374_t  c_1374_u  c_1374_v  c_1374_w  c_1374_x  c_1377_b  \n",
       "0         0         0         0         0         0         0         0  \n",
       "1         0         0         0         0         0         0         0  \n",
       "2         0         0         0         0         0         0         0  \n",
       "3         0         0         0         0         0         0         0  \n",
       "4         0         0         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 1581 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols1=pd.get_dummies(cat_cols,drop_first=True)\n",
    "cat_cols1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the features before PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "cat_cols1 = StandardScaler().fit_transform(cat_cols1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA  dimension reduction for Categorical data\n",
    "The code below has .60 for the number of components parameter. It means that scikit-learn choose the minimum number of principal components such that 60% of the variance is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=0.6, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(.6)## It explains only 60% of information of data (variance)\n",
    "#pca = PCA(n_components=100)\n",
    "print(pca)\n",
    "cat_cols2=pca.fit_transform(cat_cols1)\n",
    "#pca.explained_variance_ratio_\n",
    "pca_components=pca.n_components_\n",
    "pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02679439  0.02642671  0.02371888  0.0219521   0.02070411  0.02005309\n",
      "  0.01766455  0.01641551  0.01633338  0.01613156  0.01580698  0.01567722\n",
      "  0.01547845  0.01542775  0.01519776  0.01489218  0.0148348   0.01470454\n",
      "  0.0133095   0.01226885  0.01201531  0.01190464  0.00981621  0.00545096\n",
      "  0.00503073  0.00491301  0.00477343  0.00462125  0.0046146   0.00451329\n",
      "  0.0044433   0.00431633  0.00431042  0.00421134  0.00405427  0.00401226\n",
      "  0.00398375  0.00388442  0.00385817  0.00368885  0.00352271  0.00350337\n",
      "  0.00311637  0.00307106  0.00298952  0.00293322  0.00281204  0.00275007\n",
      "  0.00264365  0.00262202  0.00260357  0.00258301  0.00254042  0.00251813\n",
      "  0.00244518  0.00243345  0.00239394  0.00237841  0.00236005  0.00231069\n",
      "  0.00230358  0.00229672  0.00227445  0.00224102  0.00220519  0.00219626\n",
      "  0.00215202  0.00215063  0.00211001  0.00208484  0.00203609  0.00202591\n",
      "  0.00200112  0.00199126  0.00198299  0.00195782  0.00195207  0.00192911\n",
      "  0.00189559  0.00185401  0.00182853  0.00177746  0.00175396  0.00173281\n",
      "  0.00171756  0.00169587  0.00168144  0.00164927  0.00164289  0.00160718\n",
      "  0.0016046   0.00158315  0.00157214  0.00155853  0.00153863  0.00151837\n",
      "  0.00150468  0.00146908  0.00145984  0.00145318  0.00144437  0.00142247\n",
      "  0.00140847  0.00140527  0.00139815  0.00138762  0.00135472]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XlwnfV97/H39+zad1lGsrxggwFD\nWARhSSiFhJCUxGQCAzRNSAslaS7T/XaS3ks6NzeZ26SdJs0kzZRAEiChJCGbb0NCAyahcMG1zGYW\nG2TjRfImWbYsazs6Ot/7x3lkFEWWjrHsRzrn85rR6Jzn/J5H32ceWx/9fr9nMXdHREQkEnYBIiIy\nNygQREQEUCCIiEhAgSAiIoACQUREAgoEEREBFAgiIhJQIIiICKBAEBGRQCzsAo5FfX29L1myJOwy\nRETmlQ0bNvS4e8NM7eZVICxZsoT29vawyxARmVfMbHs+7TRkJCIigAJBREQCCgQREQEUCCIiElAg\niIgIoEAQEZGAAkFERIAiCYQH1u3gide6wy5DRGROK/hASGeyfOeZ7dx2X7tCQURkGgUfCIlYhO/e\n9naWN5Rz233t/FqhICIypYIPBICasgTfve3trGgs54/va2f9tt6wSxIRmXOKIhDgzVBIxSL86Nmu\nsMsREZlziiYQAKpLE5zaWM6O3oGwSxERmXOKKhAAFteWsn3/YNhliIjMOUUXCK21pew6OEQ6kw27\nFBGROaX4AqGujKxD18GhsEsREZlTii4QFteVArB9v+YRREQmKr5AqM0Fwo5ezSOIiExUdIHQUJGk\nJB7VxLKIyCR5BYKZXWNmm82sw8w+NcXnSTP7XvD5OjNbEix/t5ltMLONwfcrJ6zzq2CbzwdfjbO1\nUzPsC60600hE5LfEZmpgZlHga8C7gU5gvZmtcfdXJjS7FTjg7svN7CbgC8CNQA/wfnffZWargEeA\n5gnrfdjd22dpX/LWWleqOQQRkUny6SFcBHS4+1Z3TwMPAqsntVkN3Bu8fgi4yszM3Z9z913B8peB\nlJklZ6Pw47G4tpQdvYO4e9iliIjMGfkEQjOwc8L7Tn7zr/zfaOPuGaAPqJvU5kPAc+4+MmHZt4Lh\nojvNzKb64WZ2u5m1m1l7d/fs3JhucV0pw6NZ9vWPzNxYRKRI5BMIU/2invyn9bRtzOwscsNIH5/w\n+Yfd/WzgncHXR6b64e5+l7u3uXtbQ0NDHuXOrLWuDEDzCCIiE+QTCJ3AognvW4BdR2tjZjGgCugN\n3rcAPwY+6u5bxldw967gez/wALmhqZNi/NRTzSOIiLwpn0BYD6wws6VmlgBuAtZMarMGuCV4fT2w\n1t3dzKqBnwGfdvenxhubWczM6oPXceBa4KXj25X8NdeUEI2YrkUQEZlgxkAI5gTuIHeG0KvA9939\nZTP7rJl9IGh2D1BnZh3AXwLjp6beASwH7px0emkSeMTMXgSeB7qAb8zmjk0nHo1wSnVKQ0YiIhPM\neNopgLs/DDw8adlnJrweBm6YYr3PAZ87ymYvyL/M2ddaW8p29RBERI4ouiuVx7XWlrFDcwgiIkcU\nbSAsrivlwOAoh4ZHwy5FRGROKN5AGL/JneYRRESAIg6E1iO3wVYgiIhAEQfC0voyIgab9/aHXYqI\nyJxQtIFQmoixorGCFzsPhl2KiMicULSBAPC2RVW8sPOgbnInIkKRB8I5LdUcGByl84CerywiUtSB\ncO6iagCe36lhIxGRog6E05sqSMQimkcQEaHIAyEejXDWKZW8sLMv7FJEREJX1IEA8LaWajZ29ZEZ\ny4ZdiohIqBQIi6oYGh2jo/tw2KWIiISq6APhnJbcxPILmlgWkSJX9IGwtK6MilSMFzo1jyAixa3o\nAyESMd7WUq0egogUvaIPBIBzWqrYvKef4dGxsEsREQmNAgF426JqMlnn5V0aNhKR4qVAAC5cUosZ\nPPFaT9iliIiERoEA1JYlOL+1hrWb9oVdiohIaBQIgStXNrKxq499h4bDLkVEJBQKhMCVKxsBeHyz\negkiUpwUCIGVTRWcUpXisVcVCCJSnBQIATPjyjMaebKjR6efikhRUiBMcNXKBQymx1j3Rm/YpYiI\nnHQKhAkuObWOVDzC2lf3hl2KiMhJp0CYIBWPctmp9azdvE/PWRaRoqNAmOSqMxaws3eI9dsOhF2K\niMhJpUCY5LrzTmFBZZLP/ewVsln1EkSkeOQVCGZ2jZltNrMOM/vUFJ8nzex7wefrzGxJsPzdZrbB\nzDYG36+csM4FwfIOM/uKmdls7dTxKE3E+Jv3rOTFzj5+8nxX2OWIiJw0MwaCmUWBrwHvBc4Ebjaz\nMyc1uxU44O7LgS8BXwiW9wDvd/ezgVuA+yes83XgdmBF8HXNcezHrPrgec2c01LFF3+xmcF0Juxy\nREROinx6CBcBHe6+1d3TwIPA6kltVgP3Bq8fAq4yM3P359x9V7D8ZSAV9CYWApXu/rTnZm/vA647\n7r2ZJZGIcee1Z7Ln0DB3PbE17HJERE6KfAKhGdg54X1nsGzKNu6eAfqAukltPgQ85+4jQfvOGbYZ\nqguX1PJ7Zy/kX3+9lZGMLlQTkcKXTyBMNbY/ebZ12jZmdha5YaSPH8M2x9e93czazay9u7s7j3Jn\nz9VnLWBodIzt+wdP6s8VEQlDPoHQCSya8L4F2HW0NmYWA6qA3uB9C/Bj4KPuvmVC+5YZtgmAu9/l\n7m3u3tbQ0JBHubPn1IZyALZ2Hz6pP1dEJAz5BMJ6YIWZLTWzBHATsGZSmzXkJo0BrgfWurubWTXw\nM+DT7v7UeGN33w30m9nFwdlFHwV+epz7MuuW1pcBsKV7IORKREROvBkDIZgTuAN4BHgV+L67v2xm\nnzWzDwTN7gHqzKwD+Etg/NTUO4DlwJ1m9nzw1Rh89ifA3UAHsAX4+Wzt1GwpS8ZYWJViyz71EESk\n8MXyaeTuDwMPT1r2mQmvh4Ebpljvc8DnjrLNdmDVsRQbhlMbytnSox6CiBQ+Xak8g2UNZWzdd1j3\nNhKRgqdAmMGpDeX0j2ToPjwSdikiIieUAmEGyxqCieV9GjYSkcKmQJjB+KmnW3TqqYgUOAXCDJoq\nU5QmomzVqaciUuAUCDOIRIyl9WXqIYhIwVMg5OHUhnK29igQRKSwKRDysKyhjM4DQwyP6iZ3IlK4\nFAh5OLWhHHd4QxeoiUgBUyDk4c2b3CkQRKRwKRDy8OZN7jSPICKFS4GQh5JElObqEgWCiBQ0BUKe\nTm0s15CRiBQ0BUKezmiqYNOeQxweyYRdiojICaFAyNMVpzcyOuY8+XpP2KWIiJwQCoQ8tS2poSIV\nY+2mvWGXIiJyQigQ8hSPRrj8tAYe39xNNqtnI4hI4VEgHIOrVjbS3T/CS7v6wi5FRGTWKRCOwRWn\nN2IGj726L+xSRERmnQLhGNSWJTi/tYa1mxQIIlJ4FAjH6MqVjWzs6mPfoeGwSxERmVUKhGN05cpG\nAB7frF6CiBSWWNgFzDcrmyo4pSrFVx7r4PW9hzl/cQ2XLa+nqiQedmkiIsdFPYRjZGb87+tWsbAq\nxX3PbOeT332Wy7/4ON94YquelyAi85q5z59z6tva2ry9vT3sMo5IZ7K80HmQr67t4NevddNcXcIX\nPnQO71hRH3ZpIiJHmNkGd2+bqZ16CMchEYtw4ZJa7v2ji/jOrW+nNBHlY9/6L37QvjPs0kREjpkC\nYZa8Y0U9P/rkpVxyah3//aEX+fKjrzGfel8iIgqEWVSRivPNj13Ih85v4cuPvs7l//A4X/zFJjbv\n6Q+7NBGRGWkO4QRwd9a8sIsfPtvFUx09jGWdd52xgL+55nROW1ARdnkiUmTynUNQIJxg3f0jPPhf\nO7jria0MpDNce84pnLuomsV1pZyxsJJTqkvCLlFECtysBoKZXQP8MxAF7nb3v5/0eRK4D7gA2A/c\n6O7bzKwOeAi4EPi2u98xYZ1fAQuBoWDR1e4+7dVe8zEQxvUOpPmXxzv43vqd9AcP2YlGjNvesZQ/\ne9cKShO6JEREToxZCwQziwKvAe8GOoH1wM3u/sqENp8EznH3T5jZTcAH3f1GMysDzgNWAaumCIS/\ndve8f8PP50AY5+70DqTZ3jvI99fv5MH1O2muLuHzH1zFFac3hl2eiBSg2Tzt9CKgw923unsaeBBY\nPanNauDe4PVDwFVmZu4+4O5PArrxT8DMqCtPcn5rDX//oXP4wScuoSwZ5WPfWs9X176uM5NEJDT5\nBEIzMPHE+s5g2ZRt3D0D9AF1eWz7W2b2vJndaWaWR/uCc+GSWtbc8Q6uO/cU/vE/XuNPH3xeVzyL\nSCjyGbie6hf15D9j82kz2YfdvcvMKoAfAh8hNw/xmxs2ux24HaC1tXXmauehVDzKl248l9OaKviH\nRzbz2Kt7WdZQxrL6ci5eVsf7zm6iujQRdpkiUuDy6SF0AosmvG8Bdh2tjZnFgCqgd7qNuntX8L0f\neIDc0NRU7e5y9zZ3b2toaMij3PnJzPjkFcv57q1v58YLF1FblmT9tl7+9scbufDzj3LbvevpOjg0\n84ZERN6ifHoI64EVZrYU6AJuAn5/Ups1wC3A08D1wFqfZjA8CI1qd+8xszhwLfDoW6i/4Fy6vJ5L\nl+fuheTuvLzrED99vov7nt7Ovzzewec/eHbIFYpIoZoxENw9Y2Z3AI+QO+30m+7+spl9Fmh39zXA\nPcD9ZtZBrmdw0/j6ZrYNqAQSZnYdcDWwHXgkCIMouTD4xqzuWQEwM1Y1V7GquYqt3QM81dETdkki\nUsDyOvnd3R8GHp607DMTXg8DNxxl3SVH2ewF+ZUoAJctr+exTfvoPDBIS01p2OWISAHSvYzmifFb\nav+/jv0hVyIihUqBME+saCynoSLJkxo2EpETRIEwT5gZ71hez1MdPWSzunhNRGafAmEeuWx5PfsH\n0mzeq9tpi8jsUyDMI5ctz138rbONROREUCDMIwurSljWUKZAEJETQoEwz7xjeT3r3uglncmGXYqI\nFBgFwjxz2fJ6BtNjPLfjQNiliEiBUSDMM5eeWkciFuHnL+0JuxQRKTAKhHmmIhXnqpWN/PuLu8iM\nadhIRGaPAmEeWn1uMz2H0zy1RVcti8jsUSDMQ7+7soGKVIyfPtcVdikiUkAUCPNQMhblfasW8sjL\nexhK6+lqIjI7FAjz1OrzTmEgPcajr+4NuxQRKRAKhHnq4qV1NFWm+OnzGjYSkdmhQJinIhHjA+ee\nwq82d7Ol+3DY5YhIAVAgzGM3X9RKaSLKtV95kvuf2c40Ty0VEZmRAmEeW1pfxiN/cTltS2q48ycv\n8fvfWMePn+vkwEA67NJEZB6y+fRXZVtbm7e3t4ddxpzj7nxn3Q7++dHX6Tk8QsTgmlVN/MuH9ZRS\nEQEz2+DubTO1y+uZyjK3mRkfuXgxH76olRe7+vjXX2/h4Y176B1IU1uWCLs8EZknNGRUQCIR49xF\n1dx8USsAm/YcCrkiEZlPFAgFaOXCCgA27daT1UQkfwqEAtRQnqS2LMHmPQoEEcmfAqEAmRmnL6hg\nk569LCLHQIFQoE5vquC1Pf1ks/PnLDIRCZcCoUCdsbCCodExdvQOhl2KiMwTCoQCdXpTJQCbNI8g\nInlSIBSo0xaUY4YmlkUkbwqEAlWaiLG4tlTXIohI3hQIBez0pgr1EEQkb3kFgpldY2abzazDzD41\nxedJM/te8Pk6M1sSLK8zs8fN7LCZfXXSOheY2cZgna+Ymc3GDsmbTm+qZNv+AT1VTUTyMmMgmFkU\n+BrwXuBM4GYzO3NSs1uBA+6+HPgS8IVg+TBwJ/DXU2z668DtwIrg65q3sgNydGc0VZB1eH2fegki\nMrN8eggXAR3uvtXd08CDwOpJbVYD9wavHwKuMjNz9wF3f5JcMBxhZguBSnd/2nO3W70PuO54dkR+\n2+lNwS0sNGwkInnIJxCagZ0T3ncGy6Zs4+4ZoA+om2GbnTNsU47T4royUvGI5hFEJC/5BMJUY/uT\nL3/Np81bam9mt5tZu5m1d3d3T7NJmSwaMVY0amJZRPKTTyB0AosmvG8Bdh2tjZnFgCqgd4Zttsyw\nTQDc/S53b3P3toaGhjzKlYmWNZSxbf9A2GWIyDyQTyCsB1aY2VIzSwA3AWsmtVkD3BK8vh5Y69M8\nis3ddwP9ZnZxcHbRR4GfHnP1MqP68iS9eqSmiORhxiemuXvGzO4AHgGiwDfd/WUz+yzQ7u5rgHuA\n+82sg1zP4Kbx9c1sG1AJJMzsOuBqd38F+BPg20AJ8PPgS2ZZXXmCwfQYQ+kxShLRsMsRkTksr0do\nuvvDwMOTln1mwuth4IajrLvkKMvbgVX5FipvTV3wCM39AyO0JEpDrkZE5jJdqVzg6sqSAOw/rGEj\nEZmeAqHA1ZW/2UMQEZmOAqHAqYcgIvlSIBS4N3sICgQRmZ4CocCVJqKk4hH2H9aQkYhMT4FQ4MyM\nurKkeggiMiMFQhGoK09oDkFEZqRAKAJ1ZQmdZSQiM1IgFIHasiS96iGIyAwUCEWgvjxBz0CaaW4v\nJSKiQCgGdeUJ0pksh0cyYZciInOYAqEI1AYXp+mupyIyHQVCERi/OK1H8wgiMg0FQhGoP3L7Cp1p\nJCJHp0AoArVBD0FDRiIyHQVCEXjzmQgKBBE5OgVCEUjFo5QnY/RoyEhEpqFAKBK1ZQkNGYnItBQI\nRUL3MxKRmSgQikRdWVJDRiIyLQVCkcjd4E49BBE5OgVCkagrT3BgIE02q/sZicjUFAhFoq48SSbr\nHBoeDbsUEZmjFAhFYvxaBN2+QkSORoFQJOp0tbKIzECBUCTqdD8jEZmBAqFIHLnjqXoIInIUCoQi\nUVMaDBlpDkFEjkKBUCQSsQhVJXH2D2jISESmpkAoInVlCfb0DYddhojMUXkFgpldY2abzazDzD41\nxedJM/te8Pk6M1sy4bNPB8s3m9l7JizfZmYbzex5M2ufjZ2R6b19WR3/8cpefvbi7rBLEZE5KDZT\nAzOLAl8D3g10AuvNbI27vzKh2a3AAXdfbmY3AV8AbjSzM4GbgLOAU4BHzew0dx8L1vtdd++Zxf2R\nafzd+8/ktb39/MX3n6exMsmFS2rDLklE5pB8eggXAR3uvtXd08CDwOpJbVYD9wavHwKuMjMLlj/o\n7iPu/gbQEWxPQpCKR7n7o220VJfwx/e18/SW/bqVhYgckU8gNAM7J7zvDJZN2cbdM0AfUDfDug78\nh5ltMLPbj710eStqyhJ8+w8vIh6NcPM3nuHi//MY//MnG1m/rRd3hYNIMZtxyAiwKZZN/s1xtDbT\nrXuZu+8ys0bgl2a2yd2f+K0fnguL2wFaW1vzKFdm0lpXymN/9Ts8vmkfv3hpDz/c0MV3ntnBkrpS\nbmhbxA0XtNBYmQq7TBE5yfIJhE5g0YT3LcCuo7TpNLMYUAX0Treuu49/32dmPyY3lPRbgeDudwF3\nAbS1telP2FlSmYqz+txmVp/bzMBIhp+/tIcftO/kHx7ZzJd++RpXn7WAGy5YRH15kljUqEjFaK4u\nITcSKCKFKJ9AWA+sMLOlQBe5SeLfn9RmDXAL8DRwPbDW3d3M1gAPmNk/kZtUXgH8l5mVARF37w9e\nXw18dlb2SI5ZWTLG9Re0cP0FLbzRM8AD67bzgw2dPLxxz2+0W1RbwjtXNHDJsjpWNVexuLaUSEQB\nIVIoLJ9xYzN7H/BlIAp8090/b2afBdrdfY2ZpYD7gfPI9Qxucvetwbr/A/gjIAP8ubv/3MyWAT8O\nNh8DHnD3z89UR1tbm7e36wzVk2F4dIz2bQcYGh0jM5ZlX/8IT3b08PSW/RweyQBQlohy/uIa3n/O\nKbznrCaqSuMhVy0iUzGzDe7eNmO7+TSRqEAI3+hYlk27+3l19yFe2tXHrzZ3s6N3kHjUaK0tJRaJ\nEIsaKxrLuWx5Pe9c0UBTleYjRMKkQJCTwt3Z2NXHv7+4m66DQ4yNOSOZMTZ29R159sLFy2r52KVL\neNcZC4hFdXG8yMmWbyDkM4cgclRmxjkt1ZzTUv0by7NZZ/PeftZu2scD63bwie88y4LKJGcsrGRh\nVQkLq1LUlSeoLU3QVJViVXMVcYWFSKgUCHJCRCLGGQsrOWNhJZ/4nVN57NW9/OT5Lnb0DrKxs4/9\nk27DXZ6McfGyWs5dVE1tWZLq0jhnLKxkaX1ZSHsgUnwUCHLCRSPG1Wc1cfVZTUeWjWTGODg4yoHB\nNG90D/BkRw9PdvTw6Kv7fmPdd5+5gI9fvow23WZD5IRTIEgokrEoCyqjLKhMsbKpkveevRDInd10\ncHCU3oE0v3h5D/c/vY1fvrKX81qr+eN3LuM9ZzUR1amuIieEJpVlThtMZ3hoQyd3/+cb7OgdZFFt\nCee31lCWjFFTGucjFy/RWUwiM9BZRlJQxrLOL1/Zw/3PbKfzwBADIxkODI6yqKaE73/8Et1qQ2Qa\nCgQpeBu2H+Aj96yjpaaEB2+/hNqyRNglicxJ+QaCzvOTeeuCxTXcfUsb2/cP8gd3r+P+Z7bz+OZ9\nbOk+rNt6i7wF6iHIvPf4pn386b89R39wSw2AilSMcxdV87aWak5tLGNZfTkrFpRTmtB5FFJ8NGQk\nRSWbdfb1j9B1cJAt3QM8v/Mgz24/wGt7+xnvLCRiES5f0cD7zm7i8tMaqC9Phlu0yEmiQBAhd73D\nzt5cSKzb2svPX9rN7r5hAGrLEqxoLOf8xTVccVoD5y+u0dXSUpAUCCJTyGadFzoP8uyOg7y+t59N\ne/p5qauPTNapSMVYVFNKRSpGRSpOeTJKWTJG+fhXKkZVSZymqhTN1SUsqEyRjEX0jAiZ83QvI5Ep\nRCLGea01nNdac2TZoeFRnnq9h//s6GHfoWEODWfoOpg7tXVgJMPhkQwjmeyU20tEI1SkYiyoTLGq\nuZJVzVW01JSQjEVJxiLUlCVoqkxRltR/NZn71EMQyUM6kw2ufUizp2+YXX3D7Osfpn84w6GhUXYe\nGOKlrj56J92jaVxFMkZlSZxUPEJpIkZpIkp5MkZFKkZLTSmttaUsrE6RiOZuHz5+G/F4NEIqFqWy\nJNdL0d1i5a1QD0FkFiViERKxBDVlCZY1lE/Zxt3Z1TdMT/8II5ksw6Nj9A6k2d03zN5DufAYGs0w\nmB5jcGSM3X3DbNozyv99cTdjeZ4mW5mKUV+epL48SUNF7quxMklpPEoi6JU0ViZpri6hqSpFNGIY\nRjRiuuWHzEiBIDJLzIzm6hKaq0uOab3RsSy7Dw6z59Awo2NZRseyZMacTNbJZLMMpcdyPZHhUQ4M\npOk5nKa7f4RXdh9i3+ZhBtJjM/6MiEFjRYqmqhSNFUmqSuJUlcRpqEjSWlvKotpSassSQfBFKEvE\nFCBFSIEgErJ4NEJrXSmtdaVvaf3BdIbh0VyQDI+OsadvmK6DQ+w9NEI2GBIeHh1j76FhdvcNs6N3\nkL6hUQ4OjjI0evQwqQgm0VPxKPFoLigSwTBWIhY5EirjQ1mxiJGMRagsiVOZilNTGqe+ItebqSmN\na/J9HlAgiMxzuTmJN98vrsv/GRJ9Q6Ps7B1kZ+8gh4ZHSWeyjGSy9A9n6Bsa5dDQKMOZMdIZJz2W\nJRP0YPqHM2ztHqBvaJTDI5kZh7wS0QhNVakjD0aqKklQXRqnpaaExbVltNaWUl0WpzwRI6KeSWgU\nCCJFrKokTlVzFauaq45rO+5O1mFodIz+4VEODWXoHUjTc3iE7v4R9h7KTcTv6Rti855++oYyHBxM\nk5kUJBEjmGyPU5HKTaSXJKKUJqKUJmLBKcExypIxSuJRSuJRqkvj1JUnqStLUJKIEo0YiWiEylRc\n4XKMFAgictzMjGjwy7w8GWNhHvmSzTp7+4fZ1jPIzgODHAp6JH1Do/SPZOgfzp322z+cYd+hEQbS\nudf9w6PkMwcfjRj15Qlqy5IkooaZEYsY5ak3ry1JxiIk47nJ+FQ8SioepSwRXH+SilERfC9PxihN\n5EIoGYsUbNAoEEQkFJGIBc/XLuES6vJez90ZyeQm2wdHx+gbHKXn8Aj7B0YYGc2SyTrpTJb9AyPs\nOzRC70CabNCDGR3L0juQZvv+QQ6PZEhnsqQzWYYzY+R7Br4Z1JYmaKhIUleeIBWLkohFiB85ZdiI\nRSMkohHiUSMVj1IZ9HjGezapeJRY1IiYEbFceI2vnwjmaHK9n8RJndxXIIjIvGJmR/6ar4FjPqtr\nKu65OZLhdJaBdK5ncmj4zQsT+4dHGUqPMZzJMjiSoWcgHYTNCH1DubmX0TGfcIbYm++HRvMPm8ki\nlrvFSn15kh/+yaUn/AJHBYKIFD0zC64uj1JVGp/VbWezzuFguGtwJHdG2NDoGJlsFvfcw5/GskGY\nBL2bdCbLYDrD/mAeZv/hNKWJ6KzWNRUFgojICRSJGJWp3Km4c52ugxcREUCBICIiAQWCiIgACgQR\nEQkoEEREBFAgiIhIQIEgIiKAAkFERALz6hGaZtYNbH+Lq9cDPbNYzlxUDPsIxbGfxbCPUBz7ORf2\ncbG7N8zUaF4FwvEws/Z8nik6nxXDPkJx7Gcx7CMUx37Op33UkJGIiAAKBBERCRRTINwVdgEnQTHs\nIxTHfhbDPkJx7Oe82ceimUMQEZHpFVMPQUREplHwgWBm15jZZjPrMLNPhV3PbDGzRWb2uJm9amYv\nm9mfBctrzeyXZvZ68L0m7FqPl5lFzew5M/v34P1SM1sX7OP3zCwRdo3Hy8yqzewhM9sUHNNLCu1Y\nmtlfBP9WXzKzfzOzVCEcSzP7ppntM7OXJiyb8thZzleC30cvmtn54VX+2wo6EMwsCnwNeC9wJnCz\nmZ0ZblWzJgP8lbufAVwM/Ldg3z4FPObuK4DHgvfz3Z8Br054/wXgS8E+HgBuDaWq2fXPwC/cfSXw\nNnL7WzDH0syagT8F2tx9FRAFbqIwjuW3gWsmLTvasXsvsCL4uh34+kmqMS8FHQjARUCHu2919zTw\nILA65Jpmhbvvdvdng9f95H6BNJPbv3uDZvcC14VT4ewwsxbg94C7g/cGXAk8FDQphH2sBC4H7gFw\n97S7H6TAjiW5JzSWmFkMKAV2UwDH0t2fAHonLT7asVsN3Oc5zwDVZrbw5FQ6s0IPhGZg54T3ncGy\ngmJmS4DzgHXAAnffDbnQABrx5HADAAACJUlEQVTDq2xWfBn4GyAbvK8DDrp7JnhfCMd0GdANfCsY\nGrvbzMoooGPp7l3APwI7yAVBH7CBwjuW44527Ob076RCDwSbYllBnVZlZuXAD4E/d/dDYdczm8zs\nWmCfu2+YuHiKpvP9mMaA84Gvu/t5wADzeHhoKsEY+mpgKXAKUEZu+GSy+X4sZzKn//0WeiB0Aosm\nvG8BdoVUy6wzszi5MPiuu/8oWLx3vAsafN8XVn2z4DLgA2a2jdxw35XkegzVwbADFMYx7QQ63X1d\n8P4hcgFRSMfyXcAb7t7t7qPAj4BLKbxjOe5ox25O/04q9EBYD6wIzmRIkJvEWhNyTbMiGEu/B3jV\n3f9pwkdrgFuC17cAPz3Ztc0Wd/+0u7e4+xJyx26tu38YeBy4Pmg2r/cRwN33ADvN7PRg0VXAKxTQ\nsSQ3VHSxmZUG/3bH97GgjuUERzt2a4CPBmcbXQz0jQ8tzQUFf2Gamb2P3F+VUeCb7v75kEuaFWb2\nDuA/gY28Ob7+t+TmEb4PtJL7T3iDu0+e8Jp3zOwK4K/d/VozW0aux1ALPAf8gbuPhFnf8TKzc8lN\nnCeArcAfkvuDrWCOpZn9L+BGcmfIPQfcRm78fF4fSzP7N+AKcnc13Qv8HfATpjh2QRh+ldxZSYPA\nH7p7exh1T6XgA0FERPJT6ENGIiKSJwWCiIgACgQREQkoEEREBFAgiIhIQIEgIiKAAkFERAIKBBER\nAeD/A9WBC9vYz3A5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18b6cf9fe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The amount of variance that each PC explains\n",
    "var= pca.explained_variance_ratio_\n",
    "print(var)\n",
    "plt.plot(var)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.68   5.32   7.69   9.89  11.96  13.97  15.74  17.38  19.01  20.62\n",
      "  22.2   23.77  25.32  26.86  28.38  29.87  31.35  32.82  34.15  35.38\n",
      "  36.58  37.77  38.75  39.3   39.8   40.29  40.77  41.23  41.69  42.14\n",
      "  42.58  43.01  43.44  43.86  44.27  44.67  45.07  45.46  45.85  46.22\n",
      "  46.57  46.92  47.23  47.54  47.84  48.13  48.41  48.69  48.95  49.21\n",
      "  49.47  49.73  49.98  50.23  50.47  50.71  50.95  51.19  51.43  51.66\n",
      "  51.89  52.12  52.35  52.57  52.79  53.01  53.23  53.45  53.66  53.87\n",
      "  54.07  54.27  54.47  54.67  54.87  55.07  55.27  55.46  55.65  55.84\n",
      "  56.02  56.2   56.38  56.55  56.72  56.89  57.06  57.22  57.38  57.54\n",
      "  57.7   57.86  58.02  58.18  58.33  58.48  58.63  58.78  58.93  59.08\n",
      "  59.22  59.36  59.5   59.64  59.78  59.92  60.06]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOgiIlFCgS4iEiX+H+OORkSDEe/8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18b6cf39978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cumulative Variance explains\n",
    "var1=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "print(var1)\n",
    "plt.plot(var1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.865386</td>\n",
       "      <td>2.556807</td>\n",
       "      <td>3.681880</td>\n",
       "      <td>-15.224890</td>\n",
       "      <td>4.279613</td>\n",
       "      <td>0.147086</td>\n",
       "      <td>2.100572</td>\n",
       "      <td>-0.543714</td>\n",
       "      <td>0.372799</td>\n",
       "      <td>-0.143391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299181</td>\n",
       "      <td>-0.008618</td>\n",
       "      <td>0.619781</td>\n",
       "      <td>0.517230</td>\n",
       "      <td>0.799506</td>\n",
       "      <td>0.479193</td>\n",
       "      <td>0.843827</td>\n",
       "      <td>-0.121862</td>\n",
       "      <td>-0.036323</td>\n",
       "      <td>1.659200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.529277</td>\n",
       "      <td>-3.590833</td>\n",
       "      <td>-4.005520</td>\n",
       "      <td>-5.064366</td>\n",
       "      <td>0.788735</td>\n",
       "      <td>-0.087048</td>\n",
       "      <td>1.338029</td>\n",
       "      <td>-0.331564</td>\n",
       "      <td>-0.039704</td>\n",
       "      <td>-0.365968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705169</td>\n",
       "      <td>2.179614</td>\n",
       "      <td>-0.522191</td>\n",
       "      <td>0.808050</td>\n",
       "      <td>-0.402503</td>\n",
       "      <td>0.616112</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>-0.076488</td>\n",
       "      <td>0.600821</td>\n",
       "      <td>0.090781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.334431</td>\n",
       "      <td>-0.877170</td>\n",
       "      <td>-1.824529</td>\n",
       "      <td>5.267432</td>\n",
       "      <td>-5.525926</td>\n",
       "      <td>-0.418878</td>\n",
       "      <td>-4.789190</td>\n",
       "      <td>1.149211</td>\n",
       "      <td>-6.212808</td>\n",
       "      <td>0.693064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622233</td>\n",
       "      <td>-1.566857</td>\n",
       "      <td>-0.174112</td>\n",
       "      <td>-1.556901</td>\n",
       "      <td>-0.089777</td>\n",
       "      <td>-1.164885</td>\n",
       "      <td>0.675022</td>\n",
       "      <td>-0.842040</td>\n",
       "      <td>-0.687266</td>\n",
       "      <td>-0.205784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.332479</td>\n",
       "      <td>1.652325</td>\n",
       "      <td>-1.458106</td>\n",
       "      <td>-4.135491</td>\n",
       "      <td>-1.826478</td>\n",
       "      <td>-0.275238</td>\n",
       "      <td>-2.746400</td>\n",
       "      <td>0.612412</td>\n",
       "      <td>-3.701697</td>\n",
       "      <td>1.109242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148448</td>\n",
       "      <td>0.056956</td>\n",
       "      <td>-0.803545</td>\n",
       "      <td>-1.891400</td>\n",
       "      <td>-0.904441</td>\n",
       "      <td>-1.079570</td>\n",
       "      <td>-0.090293</td>\n",
       "      <td>-1.104750</td>\n",
       "      <td>-1.398273</td>\n",
       "      <td>-1.762685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.638207</td>\n",
       "      <td>10.395848</td>\n",
       "      <td>2.136656</td>\n",
       "      <td>3.521392</td>\n",
       "      <td>-2.238446</td>\n",
       "      <td>0.374907</td>\n",
       "      <td>17.678830</td>\n",
       "      <td>1.927444</td>\n",
       "      <td>0.415258</td>\n",
       "      <td>-10.599071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362726</td>\n",
       "      <td>-2.766235</td>\n",
       "      <td>-0.267289</td>\n",
       "      <td>0.542895</td>\n",
       "      <td>-1.148641</td>\n",
       "      <td>0.430036</td>\n",
       "      <td>2.340067</td>\n",
       "      <td>-0.171911</td>\n",
       "      <td>-3.353311</td>\n",
       "      <td>-1.382947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1         2          3         4         5          6    \\\n",
       "0  -3.865386   2.556807  3.681880 -15.224890  4.279613  0.147086   2.100572   \n",
       "1  21.529277  -3.590833 -4.005520  -5.064366  0.788735 -0.087048   1.338029   \n",
       "2  -2.334431  -0.877170 -1.824529   5.267432 -5.525926 -0.418878  -4.789190   \n",
       "3  -3.332479   1.652325 -1.458106  -4.135491 -1.826478 -0.275238  -2.746400   \n",
       "4   3.638207  10.395848  2.136656   3.521392 -2.238446  0.374907  17.678830   \n",
       "\n",
       "        7         8          9      ...          97        98        99   \\\n",
       "0 -0.543714  0.372799  -0.143391    ...     0.299181 -0.008618  0.619781   \n",
       "1 -0.331564 -0.039704  -0.365968    ...     0.705169  2.179614 -0.522191   \n",
       "2  1.149211 -6.212808   0.693064    ...    -0.622233 -1.566857 -0.174112   \n",
       "3  0.612412 -3.701697   1.109242    ...    -0.148448  0.056956 -0.803545   \n",
       "4  1.927444  0.415258 -10.599071    ...    -0.362726 -2.766235 -0.267289   \n",
       "\n",
       "        100       101       102       103       104       105       106  \n",
       "0  0.517230  0.799506  0.479193  0.843827 -0.121862 -0.036323  1.659200  \n",
       "1  0.808050 -0.402503  0.616112  0.012346 -0.076488  0.600821  0.090781  \n",
       "2 -1.556901 -0.089777 -1.164885  0.675022 -0.842040 -0.687266 -0.205784  \n",
       "3 -1.891400 -0.904441 -1.079570 -0.090293 -1.104750 -1.398273 -1.762685  \n",
       "4  0.542895 -1.148641  0.430036  2.340067 -0.171911 -3.353311 -1.382947  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols3=pd.DataFrame(cat_cols2,columns=range(pca_components))\n",
    "cat_cols3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat numerical and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.076627</td>\n",
       "      <td>-0.575677</td>\n",
       "      <td>-0.841880</td>\n",
       "      <td>2.313944</td>\n",
       "      <td>0.844188</td>\n",
       "      <td>-1.124082</td>\n",
       "      <td>-2.584006</td>\n",
       "      <td>-0.594535</td>\n",
       "      <td>0.939601</td>\n",
       "      <td>-0.818944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299181</td>\n",
       "      <td>-0.008618</td>\n",
       "      <td>0.619781</td>\n",
       "      <td>0.517230</td>\n",
       "      <td>0.799506</td>\n",
       "      <td>0.479193</td>\n",
       "      <td>0.843827</td>\n",
       "      <td>-0.121862</td>\n",
       "      <td>-0.036323</td>\n",
       "      <td>1.659200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.836042</td>\n",
       "      <td>0.261186</td>\n",
       "      <td>-0.171489</td>\n",
       "      <td>2.210323</td>\n",
       "      <td>-0.552976</td>\n",
       "      <td>-1.470234</td>\n",
       "      <td>-0.944588</td>\n",
       "      <td>-0.087564</td>\n",
       "      <td>0.673511</td>\n",
       "      <td>0.924485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705169</td>\n",
       "      <td>2.179614</td>\n",
       "      <td>-0.522191</td>\n",
       "      <td>0.808050</td>\n",
       "      <td>-0.402503</td>\n",
       "      <td>0.616112</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>-0.076488</td>\n",
       "      <td>0.600821</td>\n",
       "      <td>0.090781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.018008</td>\n",
       "      <td>3.167597</td>\n",
       "      <td>-0.223201</td>\n",
       "      <td>-1.768088</td>\n",
       "      <td>-0.478885</td>\n",
       "      <td>-2.902527</td>\n",
       "      <td>0.474748</td>\n",
       "      <td>-0.042028</td>\n",
       "      <td>-0.159062</td>\n",
       "      <td>0.415008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622233</td>\n",
       "      <td>-1.566857</td>\n",
       "      <td>-0.174112</td>\n",
       "      <td>-1.556901</td>\n",
       "      <td>-0.089777</td>\n",
       "      <td>-1.164885</td>\n",
       "      <td>0.675022</td>\n",
       "      <td>-0.842040</td>\n",
       "      <td>-0.687266</td>\n",
       "      <td>-0.205784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770249</td>\n",
       "      <td>0.819915</td>\n",
       "      <td>-0.247511</td>\n",
       "      <td>-1.506793</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>1.277786</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>1.994898</td>\n",
       "      <td>-0.369985</td>\n",
       "      <td>-0.451570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.148448</td>\n",
       "      <td>0.056956</td>\n",
       "      <td>-0.803545</td>\n",
       "      <td>-1.891400</td>\n",
       "      <td>-0.904441</td>\n",
       "      <td>-1.079570</td>\n",
       "      <td>-0.090293</td>\n",
       "      <td>-1.104750</td>\n",
       "      <td>-1.398273</td>\n",
       "      <td>-1.762685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.525670</td>\n",
       "      <td>0.431122</td>\n",
       "      <td>3.045903</td>\n",
       "      <td>1.629937</td>\n",
       "      <td>-2.787773</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>-2.714656</td>\n",
       "      <td>1.502891</td>\n",
       "      <td>0.979560</td>\n",
       "      <td>2.698379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362726</td>\n",
       "      <td>-2.766235</td>\n",
       "      <td>-0.267289</td>\n",
       "      <td>0.542895</td>\n",
       "      <td>-1.148641</td>\n",
       "      <td>0.430036</td>\n",
       "      <td>2.340067</td>\n",
       "      <td>-0.171911</td>\n",
       "      <td>-3.353311</td>\n",
       "      <td>-1.382947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  6.076627 -0.575677 -0.841880  2.313944  0.844188 -1.124082 -2.584006   \n",
       "1  3.836042  0.261186 -0.171489  2.210323 -0.552976 -1.470234 -0.944588   \n",
       "2  4.018008  3.167597 -0.223201 -1.768088 -0.478885 -2.902527  0.474748   \n",
       "3  0.770249  0.819915 -0.247511 -1.506793  0.210980  1.277786  0.028599   \n",
       "4  1.525670  0.431122  3.045903  1.629937 -2.787773  0.009762 -2.714656   \n",
       "\n",
       "        7         8         9      ...          97        98        99   \\\n",
       "0 -0.594535  0.939601 -0.818944    ...     0.299181 -0.008618  0.619781   \n",
       "1 -0.087564  0.673511  0.924485    ...     0.705169  2.179614 -0.522191   \n",
       "2 -0.042028 -0.159062  0.415008    ...    -0.622233 -1.566857 -0.174112   \n",
       "3  1.994898 -0.369985 -0.451570    ...    -0.148448  0.056956 -0.803545   \n",
       "4  1.502891  0.979560  2.698379    ...    -0.362726 -2.766235 -0.267289   \n",
       "\n",
       "        100       101       102       103       104       105       106  \n",
       "0  0.517230  0.799506  0.479193  0.843827 -0.121862 -0.036323  1.659200  \n",
       "1  0.808050 -0.402503  0.616112  0.012346 -0.076488  0.600821  0.090781  \n",
       "2 -1.556901 -0.089777 -1.164885  0.675022 -0.842040 -0.687266 -0.205784  \n",
       "3 -1.891400 -0.904441 -1.079570 -0.090293 -1.104750 -1.398273 -1.762685  \n",
       "4  0.542895 -1.148641  0.430036  2.340067 -0.171911 -3.353311 -1.382947  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data2=pd.concat([num_cols3,cat_cols3],axis=1)\n",
    "#train_data2=pd.merge(numeric_cols,cat_cols,on='id',how='outer')\n",
    "\n",
    "train_data2.shape\n",
    "train_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import lables data(dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   service_a\n",
       "0          1\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels= pd.read_csv(\"D:\\\\Capstone project\\\\Capstone Project\\\\train labels.csv\")\n",
    "train_labels1=pd.DataFrame(train_labels['service_a'])\n",
    "train_labels1.shape\n",
    "train_labels1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "            ...\n",
       "             97,  98,  99, 100, 101, 102, 103, 104, 105, 106],\n",
       "           dtype='int64', length=145)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=train_data2\n",
    "y=train_labels1\n",
    "y=np.array(train_labels1).ravel()\n",
    "names=train_data2.columns\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14644,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data= pd.read_csv(\"D:\\\\Capstone project\\\\Capstone Project\\\\test Data.csv\",low_memory=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature selection by using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.071599999999999997, 3), (0.037900000000000003, 4), (0.036200000000000003, 26), (0.0327, 0), (0.027199999999999998, 8), (0.0246, 2), (0.024199999999999999, 0), (0.020899999999999998, 28), (0.017899999999999999, 32), (0.016899999999999998, 9), (0.0161, 39), (0.014999999999999999, 16), (0.0141, 13), (0.014, 17), (0.0129, 33), (0.0121, 72), (0.0112, 1), (0.0109, 10), (0.0089999999999999993, 15), (0.0089999999999999993, 5), (0.0077000000000000002, 20), (0.0071000000000000004, 31), (0.0070000000000000001, 11), (0.0068999999999999999, 35), (0.0067999999999999996, 40), (0.0067999999999999996, 7), (0.0066, 92), (0.0066, 66), (0.0066, 63), (0.0066, 36), (0.0066, 1), (0.0064999999999999997, 38), (0.0064000000000000003, 49), (0.0063, 70), (0.0063, 22), (0.0061999999999999998, 42), (0.0061000000000000004, 6), (0.0060000000000000001, 25), (0.0060000000000000001, 14), (0.0058999999999999999, 74), (0.0057999999999999996, 34), (0.0054999999999999997, 101), (0.0054999999999999997, 23), (0.0054000000000000003, 18), (0.0053, 77), (0.0053, 19), (0.0051999999999999998, 56), (0.0051000000000000004, 78), (0.0051000000000000004, 68), (0.0051000000000000004, 27), (0.0050000000000000001, 80), (0.0050000000000000001, 76), (0.0050000000000000001, 58), (0.0050000000000000001, 47), (0.0048999999999999998, 105), (0.0047999999999999996, 88), (0.0047999999999999996, 86), (0.0047999999999999996, 75), (0.0047999999999999996, 16), (0.0047000000000000002, 91), (0.0047000000000000002, 61), (0.0047000000000000002, 41), (0.0047000000000000002, 6), (0.0045999999999999999, 103), (0.0045999999999999999, 73), (0.0045999999999999999, 62), (0.0045999999999999999, 53), (0.0045999999999999999, 13), (0.0045999999999999999, 10), (0.0044999999999999997, 95), (0.0044999999999999997, 94), (0.0044999999999999997, 52), (0.0044999999999999997, 37), (0.0044999999999999997, 12), (0.0044000000000000003, 85), (0.0044000000000000003, 83), (0.0044000000000000003, 69), (0.0044000000000000003, 57), (0.0044000000000000003, 44), (0.0044000000000000003, 27), (0.0044000000000000003, 21), (0.0043, 96), (0.0043, 90), (0.0043, 19), (0.0043, 12), (0.0041999999999999997, 98), (0.0041999999999999997, 81), (0.0041999999999999997, 65), (0.0041999999999999997, 45), (0.0041999999999999997, 33), (0.0041999999999999997, 20), (0.0041000000000000003, 99), (0.0041000000000000003, 87), (0.0041000000000000003, 30), (0.0041000000000000003, 29), (0.0041000000000000003, 4), (0.0040000000000000001, 102), (0.0040000000000000001, 79), (0.0040000000000000001, 59), (0.0040000000000000001, 55), (0.0040000000000000001, 35), (0.0040000000000000001, 32), (0.0040000000000000001, 14), (0.0040000000000000001, 11), (0.0038999999999999998, 60), (0.0038999999999999998, 46), (0.0038999999999999998, 36), (0.0038999999999999998, 26), (0.0038999999999999998, 25), (0.0038, 71), (0.0038, 24), (0.0038, 21), (0.0038, 5), (0.0037000000000000002, 93), (0.0037000000000000002, 89), (0.0037000000000000002, 82), (0.0037000000000000002, 54), (0.0037000000000000002, 43), (0.0037000000000000002, 31), (0.0037000000000000002, 28), (0.0037000000000000002, 24), (0.0037000000000000002, 18), (0.0037000000000000002, 17), (0.0035999999999999999, 64), (0.0035999999999999999, 3), (0.0035000000000000001, 37), (0.0035000000000000001, 7), (0.0033999999999999998, 100), (0.0033999999999999998, 84), (0.0033999999999999998, 67), (0.0033999999999999998, 51), (0.0033999999999999998, 34), (0.0033999999999999998, 9), (0.0033999999999999998, 8), (0.0032000000000000002, 104), (0.0032000000000000002, 97), (0.0032000000000000002, 22), (0.0030999999999999999, 48), (0.0030999999999999999, 30), (0.0030999999999999999, 29), (0.0030999999999999999, 23), (0.0030999999999999999, 2), (0.0030000000000000001, 106), (0.0027000000000000001, 15), (0.0025000000000000001, 50)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X,y)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02419528,  0.00663714,  0.00311814,  0.00361418,  0.00414967,\n",
       "        0.00383506,  0.0046518 ,  0.00354473,  0.00340341,  0.00338851])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "importances[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41,  42,  64,  38,  46,  40,   0,  66,  70,  47,  77,  54,  51,\n",
       "        55,  71, 110,  39,  48,  53,  43,  58,  69,  49,  73,  45,  78,\n",
       "         1,  74, 104, 101, 130,  76,  87, 108,  60,  80,  44,  52,  63,\n",
       "       112,  72,  61, 139,  56,  57, 115,  94,  65, 116, 106, 118, 114,\n",
       "        85,  96, 143, 126, 124,  16, 113,  99, 129,  79,   6, 141,  91,\n",
       "        10,  13, 100, 111,  50, 133, 132,  90,  75,  95,  82,  27,  59,\n",
       "       123, 107, 121, 134,  12, 128,  19, 136,  83, 103, 119,  20,  33,\n",
       "         4, 125,  68,  67, 137,  14,  93,  11,  32, 117,  35, 140,  97,\n",
       "        26,  98,  25,  36,  84,   5,  62,  21, 109,  81,  24, 127, 120,\n",
       "       131,  92,  28,  18,  17,  31, 102,   3,   7,  37, 105,   8,   9,\n",
       "        89,  34, 138, 122, 142, 135,  22,   2,  29,  30,  23,  86, 144,\n",
       "        15,  88], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature 41 (0.071631)\n",
      "2. feature 42 (0.037853)\n",
      "3. feature 64 (0.036194)\n",
      "4. feature 38 (0.032659)\n",
      "5. feature 46 (0.027224)\n",
      "6. feature 40 (0.024612)\n",
      "7. feature 0 (0.024195)\n",
      "8. feature 66 (0.020886)\n",
      "9. feature 70 (0.017887)\n",
      "10. feature 47 (0.016864)\n",
      "11. feature 77 (0.016134)\n",
      "12. feature 54 (0.015039)\n",
      "13. feature 51 (0.014059)\n",
      "14. feature 55 (0.013956)\n",
      "15. feature 71 (0.012904)\n",
      "16. feature 110 (0.012150)\n",
      "17. feature 39 (0.011156)\n",
      "18. feature 48 (0.010911)\n",
      "19. feature 53 (0.008970)\n",
      "20. feature 43 (0.008950)\n",
      "21. feature 58 (0.007748)\n",
      "22. feature 69 (0.007058)\n",
      "23. feature 49 (0.007040)\n",
      "24. feature 73 (0.006949)\n",
      "25. feature 45 (0.006846)\n",
      "26. feature 78 (0.006817)\n",
      "27. feature 1 (0.006637)\n",
      "28. feature 74 (0.006610)\n",
      "29. feature 104 (0.006574)\n",
      "30. feature 101 (0.006560)\n",
      "31. feature 130 (0.006552)\n",
      "32. feature 76 (0.006472)\n",
      "33. feature 87 (0.006401)\n",
      "34. feature 108 (0.006343)\n",
      "35. feature 60 (0.006332)\n",
      "36. feature 80 (0.006234)\n",
      "37. feature 44 (0.006148)\n",
      "38. feature 52 (0.006039)\n",
      "39. feature 63 (0.006009)\n",
      "40. feature 112 (0.005864)\n",
      "41. feature 72 (0.005781)\n",
      "42. feature 61 (0.005496)\n",
      "43. feature 139 (0.005460)\n",
      "44. feature 56 (0.005401)\n",
      "45. feature 57 (0.005319)\n",
      "46. feature 115 (0.005317)\n",
      "47. feature 94 (0.005194)\n",
      "48. feature 65 (0.005116)\n",
      "49. feature 116 (0.005084)\n",
      "50. feature 106 (0.005066)\n",
      "51. feature 118 (0.005037)\n",
      "52. feature 114 (0.005009)\n",
      "53. feature 85 (0.004998)\n",
      "54. feature 96 (0.004970)\n",
      "55. feature 143 (0.004910)\n",
      "56. feature 126 (0.004824)\n",
      "57. feature 124 (0.004798)\n",
      "58. feature 16 (0.004786)\n",
      "59. feature 113 (0.004781)\n",
      "60. feature 99 (0.004683)\n",
      "61. feature 129 (0.004676)\n",
      "62. feature 79 (0.004670)\n",
      "63. feature 6 (0.004652)\n",
      "64. feature 141 (0.004613)\n",
      "65. feature 91 (0.004605)\n",
      "66. feature 10 (0.004588)\n",
      "67. feature 13 (0.004571)\n",
      "68. feature 100 (0.004568)\n",
      "69. feature 111 (0.004554)\n",
      "70. feature 50 (0.004539)\n",
      "71. feature 133 (0.004513)\n",
      "72. feature 132 (0.004492)\n",
      "73. feature 90 (0.004458)\n",
      "74. feature 75 (0.004456)\n",
      "75. feature 95 (0.004449)\n",
      "76. feature 82 (0.004438)\n",
      "77. feature 27 (0.004431)\n",
      "78. feature 59 (0.004427)\n",
      "79. feature 123 (0.004402)\n",
      "80. feature 107 (0.004384)\n",
      "81. feature 121 (0.004382)\n",
      "82. feature 134 (0.004348)\n",
      "83. feature 12 (0.004332)\n",
      "84. feature 128 (0.004270)\n",
      "85. feature 19 (0.004268)\n",
      "86. feature 136 (0.004236)\n",
      "87. feature 83 (0.004204)\n",
      "88. feature 103 (0.004195)\n",
      "89. feature 119 (0.004180)\n",
      "90. feature 20 (0.004175)\n",
      "91. feature 33 (0.004155)\n",
      "92. feature 4 (0.004150)\n",
      "93. feature 125 (0.004101)\n",
      "94. feature 68 (0.004093)\n",
      "95. feature 67 (0.004079)\n",
      "96. feature 137 (0.004060)\n",
      "97. feature 14 (0.004022)\n",
      "98. feature 93 (0.004021)\n",
      "99. feature 11 (0.004009)\n",
      "100. feature 32 (0.004008)\n",
      "101. feature 117 (0.003983)\n",
      "102. feature 35 (0.003975)\n",
      "103. feature 140 (0.003966)\n",
      "104. feature 97 (0.003964)\n",
      "105. feature 26 (0.003927)\n",
      "106. feature 98 (0.003921)\n",
      "107. feature 25 (0.003920)\n",
      "108. feature 36 (0.003891)\n",
      "109. feature 84 (0.003864)\n",
      "110. feature 5 (0.003835)\n",
      "111. feature 62 (0.003814)\n",
      "112. feature 21 (0.003782)\n",
      "113. feature 109 (0.003753)\n",
      "114. feature 81 (0.003743)\n",
      "115. feature 24 (0.003735)\n",
      "116. feature 127 (0.003731)\n",
      "117. feature 120 (0.003718)\n",
      "118. feature 131 (0.003699)\n",
      "119. feature 92 (0.003682)\n",
      "120. feature 28 (0.003674)\n",
      "121. feature 18 (0.003671)\n",
      "122. feature 17 (0.003670)\n",
      "123. feature 31 (0.003659)\n",
      "124. feature 102 (0.003627)\n",
      "125. feature 3 (0.003614)\n",
      "126. feature 7 (0.003545)\n",
      "127. feature 37 (0.003499)\n",
      "128. feature 105 (0.003446)\n",
      "129. feature 8 (0.003403)\n",
      "130. feature 9 (0.003389)\n",
      "131. feature 89 (0.003383)\n",
      "132. feature 34 (0.003375)\n",
      "133. feature 138 (0.003371)\n",
      "134. feature 122 (0.003363)\n",
      "135. feature 142 (0.003206)\n",
      "136. feature 135 (0.003203)\n",
      "137. feature 22 (0.003179)\n",
      "138. feature 2 (0.003118)\n",
      "139. feature 29 (0.003091)\n",
      "140. feature 30 (0.003080)\n",
      "141. feature 23 (0.003078)\n",
      "142. feature 86 (0.003065)\n",
      "143. feature 144 (0.002966)\n",
      "144. feature 15 (0.002668)\n",
      "145. feature 88 (0.002479)\n"
     ]
    }
   ],
   "source": [
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=xgboost.XGBClassifier()\n",
    "model.fit(np.array(X),y)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields release, c_0327, c_0328, c_0329, c_0330, c_0331, c_0332, c_0333, c_0334, c_0335, c_0336, c_0337, c_0338, c_0339, c_0340, c_0341, c_0342, c_0343, c_0344, c_0345, c_0346, c_0347, c_0348, c_0349, c_0350, c_0351, c_0352, c_0353, c_0354, c_0355, c_0356, c_0357, c_0358, c_0359, c_0360, c_0361, c_0362, c_0363, c_0364, c_0365, c_0366, c_0367, c_0368, c_0369, c_0370, c_0371, c_0372, c_0373, c_0374, c_0376, c_0377, c_0378, c_0379, c_0380, c_0381, c_0382, c_0383, c_0384, c_0385, c_0386, c_0387, c_0388, c_0389, c_0390, c_0391, c_0392, c_0393, c_0394, c_0395, c_0396, c_0397, c_0398, c_0399, c_0400, c_0401, c_0402, c_0403, c_0404, c_0405, c_0406, c_0408, c_0409, c_0410, c_0412, c_0413, c_0414, c_0415, c_0416, c_0417, c_0418, c_0419, c_0420, c_0421, c_0422, c_0423, c_0424, c_0425, c_0426, c_0427, c_0428, c_0429, c_0430, c_0432, c_0433, c_0434, c_0435, c_0436, c_0437, c_0438, c_0439, c_0440, c_0441, c_0442, c_0443, c_0444, c_0445, c_0447, c_0448, c_0449, c_0450, c_0451, c_0452, c_0453, c_0454, c_0455, c_0456, c_0457, c_0458, c_0459, c_0460, c_0461, c_0462, c_0463, c_0464, c_0465, c_0466, c_0467, c_0468, c_0469, c_0470, c_0471, c_0472, c_0473, c_0474, c_0475, c_0476, c_0477, c_0478, c_0480, c_0481, c_0482, c_0483, c_0485, c_0486, c_0487, c_0488, c_0489, c_0491, c_0492, c_0493, c_0494, c_0495, c_0496, c_0497, c_0498, c_0499, c_0500, c_0501, c_0502, c_0503, c_0504, c_0505, c_0506, c_0507, c_0508, c_0509, c_0510, c_0511, c_0512, c_0513, c_0514, c_0516, c_0517, c_0518, c_0520, c_0521, c_0522, c_0523, c_0524, c_0525, c_0526, c_0527, c_0528, c_0530, c_0531, c_0532, c_0533, c_0534, c_0535, c_0537, c_0538, c_0539, c_0540, c_0542, c_0543, c_0544, c_0545, c_0546, c_0547, c_0548, c_0549, c_0550, c_0551, c_0552, c_0553, c_0554, c_0555, c_0556, c_0557, c_0558, c_0559, c_0560, c_0561, c_0562, c_0563, c_0564, c_0565, c_0566, c_0567, c_0568, c_0569, c_0570, c_0572, c_0573, c_0574, c_0575, c_0576, c_0577, c_0578, c_0579, c_0580, c_0581, c_0582, c_0583, c_0584, c_0585, c_0586, c_0587, c_0588, c_0589, c_0590, c_0591, c_0592, c_0593, c_0595, c_0596, c_0597, c_0599, c_0600, c_0601, c_0605, c_0606, c_0607, c_0608, c_0609, c_0610, c_0611, c_0612, c_0613, c_0614, c_0615, c_0616, c_0617, c_0618, c_0619, c_0620, c_0621, c_0622, c_0623, c_0624, c_0625, c_0626, c_0628, c_0629, c_0631, c_0633, c_0634, c_0635, c_0636, c_0637, c_0638, c_0639, c_0640, c_0641, c_0642, c_0643, c_0645, c_0646, c_0647, c_0648, c_0649, c_0650, c_0651, c_0652, c_0653, c_0654, c_0655, c_0656, c_0657, c_0658, c_0659, c_0660, c_0661, c_0662, c_0663, c_0664, c_0665, c_0666, c_0667, c_0668, c_0669, c_0670, c_0671, c_0672, c_0673, c_0674, c_0675, c_0676, c_0677, c_0678, c_0679, c_0680, c_0681, c_0682, c_0683, c_0684, c_0685, c_0686, c_0687, c_0688, c_0689, c_0690, c_0691, c_0692, c_0694, c_0695, c_0696, c_0697, c_0698, c_0699, c_0700, c_0701, c_0702, c_0703, c_0704, c_0706, c_0707, c_0709, c_0711, c_0712, c_0713, c_0714, c_0715, c_0716, c_0717, c_0718, c_0719, c_0720, c_0721, c_0722, c_0723, c_0724, c_0725, c_0726, c_0727, c_0728, c_0729, c_0730, c_0731, c_0732, c_0733, c_0734, c_0735, c_0736, c_0737, c_0738, c_0739, c_0740, c_0742, c_0743, c_0744, c_0745, c_0746, c_0747, c_0748, c_0749, c_0750, c_0751, c_0752, c_0755, c_0756, c_0757, c_0758, c_0759, c_0760, c_0761, c_0762, c_0764, c_0765, c_0766, c_0767, c_0768, c_0769, c_0770, c_0771, c_0772, c_0773, c_0774, c_0775, c_0776, c_0777, c_0778, c_0779, c_0780, c_0781, c_0782, c_0783, c_0785, c_0786, c_0787, c_0788, c_0789, c_0790, c_0791, c_0792, c_0793, c_0794, c_0795, c_0796, c_0797, c_0798, c_0799, c_0800, c_0801, c_0802, c_0803, c_0804, c_0805, c_0806, c_0807, c_0808, c_0809, c_0810, c_0812, c_0813, c_0814, c_0815, c_0816, c_0817, c_0818, c_0819, c_0820, c_0822, c_0823, c_0824, c_0825, c_0826, c_0827, c_0828, c_0829, c_0830, c_0831, c_0832, c_0833, c_0834, c_0835, c_0836, c_0837, c_0838, c_0839, c_0840, c_0841, c_0842, c_0843, c_0844, c_0845, c_0846, c_0847, c_0849, c_0850, c_0851, c_0852, c_0853, c_0854, c_0855, c_0856, c_0857, c_0858, c_0859, c_0860, c_0861, c_0862, c_0863, c_0864, c_0865, c_0866, c_0867, c_0868, c_0869, c_0870, c_0871, c_0872, c_0873, c_0874, c_0875, c_0876, c_0877, c_0880, c_0881, c_0882, c_0883, c_0884, c_0885, c_0886, c_0887, c_0888, c_0889, c_0890, c_0891, c_0892, c_0893, c_0894, c_0895, c_0896, c_0897, c_0898, c_0899, c_0900, c_0901, c_0902, c_0903, c_0904, c_0905, c_0906, c_0907, c_0908, c_0909, c_0910, c_0911, c_0913, c_0914, c_0915, c_0916, c_0917, c_0918, c_0919, c_0920, c_0921, c_0922, c_0923, c_0924, c_0925, c_0926, c_0927, c_0928, c_0929, c_0930, c_0931, c_0932, c_0933, c_0935, c_0936, c_0937, c_0938, c_0939, c_0940, c_0941, c_0942, c_0943, c_0944, c_0945, c_0946, c_0947, c_0948, c_0949, c_0951, c_0952, c_0953, c_0954, c_0955, c_0956, c_0957, c_0958, c_0959, c_0960, c_0961, c_0962, c_0963, c_0964, c_0965, c_0966, c_0968, c_0970, c_0971, c_0972, c_0973, c_0974, c_0975, c_0976, c_0977, c_0978, c_0979, c_0980, c_0981, c_0982, c_0983, c_0984, c_0985, c_0986, c_0987, c_0988, c_0989, c_0990, c_0991, c_0992, c_0993, c_0994, c_0995, c_0996, c_0997, c_0998, c_1000, c_1001, c_1002, c_1003, c_1004, c_1005, c_1006, c_1008, c_1009, c_1010, c_1011, c_1012, c_1013, c_1014, c_1015, c_1016, c_1017, c_1018, c_1019, c_1020, c_1021, c_1022, c_1023, c_1024, c_1025, c_1026, c_1027, c_1028, c_1029, c_1031, c_1032, c_1033, c_1035, c_1036, c_1037, c_1038, c_1039, c_1040, c_1041, c_1042, c_1043, c_1044, c_1045, c_1046, c_1047, c_1048, c_1049, c_1050, c_1051, c_1052, c_1053, c_1054, c_1055, c_1056, c_1057, c_1058, c_1059, c_1060, c_1061, c_1062, c_1063, c_1064, c_1065, c_1066, c_1067, c_1068, c_1069, c_1070, c_1071, c_1073, c_1074, c_1075, c_1076, c_1077, c_1078, c_1079, c_1080, c_1081, c_1082, c_1083, c_1084, c_1085, c_1086, c_1087, c_1088, c_1089, c_1090, c_1091, c_1092, c_1093, c_1094, c_1095, c_1096, c_1097, c_1098, c_1099, c_1100, c_1101, c_1102, c_1103, c_1104, c_1105, c_1106, c_1107, c_1108, c_1109, c_1110, c_1111, c_1112, c_1113, c_1114, c_1115, c_1116, c_1117, c_1118, c_1119, c_1120, c_1121, c_1122, c_1123, c_1124, c_1125, c_1126, c_1127, c_1128, c_1129, c_1130, c_1131, c_1132, c_1133, c_1134, c_1135, c_1136, c_1137, c_1139, c_1140, c_1141, c_1142, c_1143, c_1144, c_1145, c_1146, c_1147, c_1148, c_1149, c_1150, c_1151, c_1152, c_1153, c_1154, c_1155, c_1157, c_1158, c_1159, c_1160, c_1161, c_1162, c_1163, c_1164, c_1165, c_1166, c_1167, c_1169, c_1170, c_1171, c_1172, c_1173, c_1174, c_1175, c_1176, c_1177, c_1178, c_1180, c_1181, c_1182, c_1183, c_1185, c_1186, c_1187, c_1188, c_1189, c_1190, c_1191, c_1192, c_1193, c_1194, c_1195, c_1196, c_1197, c_1198, c_1199, c_1200, c_1201, c_1202, c_1203, c_1204, c_1205, c_1206, c_1207, c_1208, c_1209, c_1210, c_1211, c_1212, c_1213, c_1214, c_1215, c_1216, c_1217, c_1218, c_1219, c_1220, c_1221, c_1222, c_1223, c_1224, c_1225, c_1226, c_1227, c_1229, c_1230, c_1231, c_1232, c_1234, c_1235, c_1236, c_1237, c_1238, c_1239, c_1240, c_1241, c_1243, c_1244, c_1245, c_1246, c_1247, c_1248, c_1249, c_1250, c_1251, c_1252, c_1253, c_1254, c_1255, c_1256, c_1258, c_1259, c_1260, c_1263, c_1264, c_1265, c_1266, c_1267, c_1268, c_1269, c_1270, c_1271, c_1272, c_1273, c_1274, c_1275, c_1276, c_1278, c_1280, c_1282, c_1283, c_1284, c_1285, c_1286, c_1287, c_1288, c_1289, c_1290, c_1291, c_1292, c_1293, c_1294, c_1295, c_1296, c_1297, c_1298, c_1299, c_1300, c_1301, c_1302, c_1303, c_1304, c_1305, c_1306, c_1307, c_1309, c_1310, c_1311, c_1312, c_1313, c_1314, c_1315, c_1316, c_1317, c_1318, c_1319, c_1320, c_1321, c_1322, c_1323, c_1324, c_1325, c_1326, c_1327, c_1328, c_1329, c_1330, c_1331, c_1332, c_1333, c_1334, c_1335, c_1336, c_1337, c_1338, c_1339, c_1340, c_1341, c_1342, c_1343, c_1344, c_1345, c_1346, c_1347, c_1348, c_1350, c_1351, c_1352, c_1353, c_1354, c_1355, c_1356, c_1357, c_1359, c_1361, c_1362, c_1363, c_1364, c_1365, c_1366, c_1367, c_1368, c_1369, c_1370, c_1371, c_1372, c_1373, c_1374, c_1375, c_1377",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-0e01e0e48ded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make predictions for test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[0mtest_dmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m         class_probs = self.booster().predict(test_dmatrix,\n\u001b[0;32m    464\u001b[0m                                              \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    253\u001b[0m         data, feature_names, feature_types = _maybe_pandas_data(data,\n\u001b[0;32m    254\u001b[0m                                                                 \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                                                                 feature_types)\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_pandas_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    179\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[0;32m    180\u001b[0m Did not expect the data types in fields \"\"\"\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields release, c_0327, c_0328, c_0329, c_0330, c_0331, c_0332, c_0333, c_0334, c_0335, c_0336, c_0337, c_0338, c_0339, c_0340, c_0341, c_0342, c_0343, c_0344, c_0345, c_0346, c_0347, c_0348, c_0349, c_0350, c_0351, c_0352, c_0353, c_0354, c_0355, c_0356, c_0357, c_0358, c_0359, c_0360, c_0361, c_0362, c_0363, c_0364, c_0365, c_0366, c_0367, c_0368, c_0369, c_0370, c_0371, c_0372, c_0373, c_0374, c_0376, c_0377, c_0378, c_0379, c_0380, c_0381, c_0382, c_0383, c_0384, c_0385, c_0386, c_0387, c_0388, c_0389, c_0390, c_0391, c_0392, c_0393, c_0394, c_0395, c_0396, c_0397, c_0398, c_0399, c_0400, c_0401, c_0402, c_0403, c_0404, c_0405, c_0406, c_0408, c_0409, c_0410, c_0412, c_0413, c_0414, c_0415, c_0416, c_0417, c_0418, c_0419, c_0420, c_0421, c_0422, c_0423, c_0424, c_0425, c_0426, c_0427, c_0428, c_0429, c_0430, c_0432, c_0433, c_0434, c_0435, c_0436, c_0437, c_0438, c_0439, c_0440, c_0441, c_0442, c_0443, c_0444, c_0445, c_0447, c_0448, c_0449, c_0450, c_0451, c_0452, c_0453, c_0454, c_0455, c_0456, c_0457, c_0458, c_0459, c_0460, c_0461, c_0462, c_0463, c_0464, c_0465, c_0466, c_0467, c_0468, c_0469, c_0470, c_0471, c_0472, c_0473, c_0474, c_0475, c_0476, c_0477, c_0478, c_0480, c_0481, c_0482, c_0483, c_0485, c_0486, c_0487, c_0488, c_0489, c_0491, c_0492, c_0493, c_0494, c_0495, c_0496, c_0497, c_0498, c_0499, c_0500, c_0501, c_0502, c_0503, c_0504, c_0505, c_0506, c_0507, c_0508, c_0509, c_0510, c_0511, c_0512, c_0513, c_0514, c_0516, c_0517, c_0518, c_0520, c_0521, c_0522, c_0523, c_0524, c_0525, c_0526, c_0527, c_0528, c_0530, c_0531, c_0532, c_0533, c_0534, c_0535, c_0537, c_0538, c_0539, c_0540, c_0542, c_0543, c_0544, c_0545, c_0546, c_0547, c_0548, c_0549, c_0550, c_0551, c_0552, c_0553, c_0554, c_0555, c_0556, c_0557, c_0558, c_0559, c_0560, c_0561, c_0562, c_0563, c_0564, c_0565, c_0566, c_0567, c_0568, c_0569, c_0570, c_0572, c_0573, c_0574, c_0575, c_0576, c_0577, c_0578, c_0579, c_0580, c_0581, c_0582, c_0583, c_0584, c_0585, c_0586, c_0587, c_0588, c_0589, c_0590, c_0591, c_0592, c_0593, c_0595, c_0596, c_0597, c_0599, c_0600, c_0601, c_0605, c_0606, c_0607, c_0608, c_0609, c_0610, c_0611, c_0612, c_0613, c_0614, c_0615, c_0616, c_0617, c_0618, c_0619, c_0620, c_0621, c_0622, c_0623, c_0624, c_0625, c_0626, c_0628, c_0629, c_0631, c_0633, c_0634, c_0635, c_0636, c_0637, c_0638, c_0639, c_0640, c_0641, c_0642, c_0643, c_0645, c_0646, c_0647, c_0648, c_0649, c_0650, c_0651, c_0652, c_0653, c_0654, c_0655, c_0656, c_0657, c_0658, c_0659, c_0660, c_0661, c_0662, c_0663, c_0664, c_0665, c_0666, c_0667, c_0668, c_0669, c_0670, c_0671, c_0672, c_0673, c_0674, c_0675, c_0676, c_0677, c_0678, c_0679, c_0680, c_0681, c_0682, c_0683, c_0684, c_0685, c_0686, c_0687, c_0688, c_0689, c_0690, c_0691, c_0692, c_0694, c_0695, c_0696, c_0697, c_0698, c_0699, c_0700, c_0701, c_0702, c_0703, c_0704, c_0706, c_0707, c_0709, c_0711, c_0712, c_0713, c_0714, c_0715, c_0716, c_0717, c_0718, c_0719, c_0720, c_0721, c_0722, c_0723, c_0724, c_0725, c_0726, c_0727, c_0728, c_0729, c_0730, c_0731, c_0732, c_0733, c_0734, c_0735, c_0736, c_0737, c_0738, c_0739, c_0740, c_0742, c_0743, c_0744, c_0745, c_0746, c_0747, c_0748, c_0749, c_0750, c_0751, c_0752, c_0755, c_0756, c_0757, c_0758, c_0759, c_0760, c_0761, c_0762, c_0764, c_0765, c_0766, c_0767, c_0768, c_0769, c_0770, c_0771, c_0772, c_0773, c_0774, c_0775, c_0776, c_0777, c_0778, c_0779, c_0780, c_0781, c_0782, c_0783, c_0785, c_0786, c_0787, c_0788, c_0789, c_0790, c_0791, c_0792, c_0793, c_0794, c_0795, c_0796, c_0797, c_0798, c_0799, c_0800, c_0801, c_0802, c_0803, c_0804, c_0805, c_0806, c_0807, c_0808, c_0809, c_0810, c_0812, c_0813, c_0814, c_0815, c_0816, c_0817, c_0818, c_0819, c_0820, c_0822, c_0823, c_0824, c_0825, c_0826, c_0827, c_0828, c_0829, c_0830, c_0831, c_0832, c_0833, c_0834, c_0835, c_0836, c_0837, c_0838, c_0839, c_0840, c_0841, c_0842, c_0843, c_0844, c_0845, c_0846, c_0847, c_0849, c_0850, c_0851, c_0852, c_0853, c_0854, c_0855, c_0856, c_0857, c_0858, c_0859, c_0860, c_0861, c_0862, c_0863, c_0864, c_0865, c_0866, c_0867, c_0868, c_0869, c_0870, c_0871, c_0872, c_0873, c_0874, c_0875, c_0876, c_0877, c_0880, c_0881, c_0882, c_0883, c_0884, c_0885, c_0886, c_0887, c_0888, c_0889, c_0890, c_0891, c_0892, c_0893, c_0894, c_0895, c_0896, c_0897, c_0898, c_0899, c_0900, c_0901, c_0902, c_0903, c_0904, c_0905, c_0906, c_0907, c_0908, c_0909, c_0910, c_0911, c_0913, c_0914, c_0915, c_0916, c_0917, c_0918, c_0919, c_0920, c_0921, c_0922, c_0923, c_0924, c_0925, c_0926, c_0927, c_0928, c_0929, c_0930, c_0931, c_0932, c_0933, c_0935, c_0936, c_0937, c_0938, c_0939, c_0940, c_0941, c_0942, c_0943, c_0944, c_0945, c_0946, c_0947, c_0948, c_0949, c_0951, c_0952, c_0953, c_0954, c_0955, c_0956, c_0957, c_0958, c_0959, c_0960, c_0961, c_0962, c_0963, c_0964, c_0965, c_0966, c_0968, c_0970, c_0971, c_0972, c_0973, c_0974, c_0975, c_0976, c_0977, c_0978, c_0979, c_0980, c_0981, c_0982, c_0983, c_0984, c_0985, c_0986, c_0987, c_0988, c_0989, c_0990, c_0991, c_0992, c_0993, c_0994, c_0995, c_0996, c_0997, c_0998, c_1000, c_1001, c_1002, c_1003, c_1004, c_1005, c_1006, c_1008, c_1009, c_1010, c_1011, c_1012, c_1013, c_1014, c_1015, c_1016, c_1017, c_1018, c_1019, c_1020, c_1021, c_1022, c_1023, c_1024, c_1025, c_1026, c_1027, c_1028, c_1029, c_1031, c_1032, c_1033, c_1035, c_1036, c_1037, c_1038, c_1039, c_1040, c_1041, c_1042, c_1043, c_1044, c_1045, c_1046, c_1047, c_1048, c_1049, c_1050, c_1051, c_1052, c_1053, c_1054, c_1055, c_1056, c_1057, c_1058, c_1059, c_1060, c_1061, c_1062, c_1063, c_1064, c_1065, c_1066, c_1067, c_1068, c_1069, c_1070, c_1071, c_1073, c_1074, c_1075, c_1076, c_1077, c_1078, c_1079, c_1080, c_1081, c_1082, c_1083, c_1084, c_1085, c_1086, c_1087, c_1088, c_1089, c_1090, c_1091, c_1092, c_1093, c_1094, c_1095, c_1096, c_1097, c_1098, c_1099, c_1100, c_1101, c_1102, c_1103, c_1104, c_1105, c_1106, c_1107, c_1108, c_1109, c_1110, c_1111, c_1112, c_1113, c_1114, c_1115, c_1116, c_1117, c_1118, c_1119, c_1120, c_1121, c_1122, c_1123, c_1124, c_1125, c_1126, c_1127, c_1128, c_1129, c_1130, c_1131, c_1132, c_1133, c_1134, c_1135, c_1136, c_1137, c_1139, c_1140, c_1141, c_1142, c_1143, c_1144, c_1145, c_1146, c_1147, c_1148, c_1149, c_1150, c_1151, c_1152, c_1153, c_1154, c_1155, c_1157, c_1158, c_1159, c_1160, c_1161, c_1162, c_1163, c_1164, c_1165, c_1166, c_1167, c_1169, c_1170, c_1171, c_1172, c_1173, c_1174, c_1175, c_1176, c_1177, c_1178, c_1180, c_1181, c_1182, c_1183, c_1185, c_1186, c_1187, c_1188, c_1189, c_1190, c_1191, c_1192, c_1193, c_1194, c_1195, c_1196, c_1197, c_1198, c_1199, c_1200, c_1201, c_1202, c_1203, c_1204, c_1205, c_1206, c_1207, c_1208, c_1209, c_1210, c_1211, c_1212, c_1213, c_1214, c_1215, c_1216, c_1217, c_1218, c_1219, c_1220, c_1221, c_1222, c_1223, c_1224, c_1225, c_1226, c_1227, c_1229, c_1230, c_1231, c_1232, c_1234, c_1235, c_1236, c_1237, c_1238, c_1239, c_1240, c_1241, c_1243, c_1244, c_1245, c_1246, c_1247, c_1248, c_1249, c_1250, c_1251, c_1252, c_1253, c_1254, c_1255, c_1256, c_1258, c_1259, c_1260, c_1263, c_1264, c_1265, c_1266, c_1267, c_1268, c_1269, c_1270, c_1271, c_1272, c_1273, c_1274, c_1275, c_1276, c_1278, c_1280, c_1282, c_1283, c_1284, c_1285, c_1286, c_1287, c_1288, c_1289, c_1290, c_1291, c_1292, c_1293, c_1294, c_1295, c_1296, c_1297, c_1298, c_1299, c_1300, c_1301, c_1302, c_1303, c_1304, c_1305, c_1306, c_1307, c_1309, c_1310, c_1311, c_1312, c_1313, c_1314, c_1315, c_1316, c_1317, c_1318, c_1319, c_1320, c_1321, c_1322, c_1323, c_1324, c_1325, c_1326, c_1327, c_1328, c_1329, c_1330, c_1331, c_1332, c_1333, c_1334, c_1335, c_1336, c_1337, c_1338, c_1339, c_1340, c_1341, c_1342, c_1343, c_1344, c_1345, c_1346, c_1347, c_1348, c_1350, c_1351, c_1352, c_1353, c_1354, c_1355, c_1356, c_1357, c_1359, c_1361, c_1362, c_1363, c_1364, c_1365, c_1366, c_1367, c_1368, c_1369, c_1370, c_1371, c_1372, c_1373, c_1374, c_1375, c_1377"
     ]
    }
   ],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(test_data)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model)\n",
    "plt.title(\"xgboost.plot_importance(model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"cover\")\n",
    "plt.title('xgboost.plot_importance(model, importance_type=\"cover\")')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost.plot_importance(model, importance_type=\"gain\")\n",
    "pl.title('xgboost.plot_importance(model, importance_type=\"gain\")')\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
